{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/26 23:45:21 WARN Utils: Your hostname, dtdat resolves to a loopback address: 127.0.1.1; using 192.168.2.12 instead (on interface wlp0s20f3)\n",
      "24/12/26 23:45:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/26 23:45:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Imputer, StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType, IntegerType\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LoanPredictionConsumer\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.2.12:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>LoanPredictionConsumer</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x71c5cad44850>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"LoanID\", StringType(), True),\n",
    "    StructField(\"Age\", IntegerType(), True),\n",
    "    StructField(\"Income\", IntegerType(), True),\n",
    "    StructField(\"LoanAmount\", IntegerType(), True),\n",
    "    StructField(\"CreditScore\", IntegerType(), True),\n",
    "    StructField(\"MonthsEmployed\", IntegerType(), True),\n",
    "    StructField(\"NumCreditLines\", IntegerType(), True),\n",
    "    StructField(\"InterestRate\", DoubleType(), True),\n",
    "    StructField(\"LoanTerm\", IntegerType(), True),\n",
    "    StructField(\"DTIRatio\", DoubleType(), True),\n",
    "    StructField(\"Education\", StringType(), True),\n",
    "    StructField(\"EmploymentType\", StringType(), True),\n",
    "    StructField(\"MaritalStatus\", StringType(), True),\n",
    "    StructField(\"HasMortgage\", StringType(), True),\n",
    "    StructField(\"HasDependents\", StringType(), True),\n",
    "    StructField(\"LoanPurpose\", StringType(), True),\n",
    "    StructField(\"HasCoSigner\", StringType(), True),\n",
    "    StructField(\"Default\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = KafkaConsumer(\n",
    "    'loan_application',\n",
    "    bootstrap_servers='localhost:9092',\n",
    "    auto_offset_reset='earliest',\n",
    "    enable_auto_commit=True,\n",
    "    value_deserializer=lambda x: json.loads(x.decode('utf-8'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "model_path = \"/home/drissdo/Desktop/Scalable-Distributed-Systems/ML/model\"\n",
    "lr_model = LogisticRegressionModel.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexing_data(loan_data):\n",
    "    education_map = {'High School':1, 'Bachelor':0, 'Master':2, 'PhD':3}\n",
    "    employment_map = {'Full-time':3, 'Part-time':0, 'Self-employed':2, 'Unemployed':1}\n",
    "    marital_status_map = {'Single': 2, 'Married': 0, 'Divorced': 1}\n",
    "    has_mortgage_map = {'Yes': 1, 'No': 0}\n",
    "    has_dependents_map = {'Yes': 1, 'No': 0}\n",
    "    loan_purpose_map = {'Home':1, 'Other': 3, 'Education':2, 'Business':0, 'Auto': 4}\n",
    "    has_cosigner_map = {'Yes': 1, 'No': 0}\n",
    "    \n",
    "    loan_data['Education'] = education_map[loan_data['Education']]\n",
    "    loan_data['EmploymentType'] = employment_map[loan_data['EmploymentType']]\n",
    "    loan_data['MaritalStatus'] = marital_status_map[loan_data['MaritalStatus']]\n",
    "    loan_data['HasMortgage'] = has_mortgage_map[loan_data['HasMortgage']]\n",
    "    loan_data['HasDependents'] = has_dependents_map[loan_data['HasDependents']]\n",
    "    loan_data['LoanPurpose'] = loan_purpose_map[loan_data['LoanPurpose']]\n",
    "    loan_data['HasCoSigner'] = has_cosigner_map[loan_data['HasCoSigner']]\n",
    "    \n",
    "    \n",
    "    return loan_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "{'LoanID': '368bafbc-73e1-46e1-ab17-2f3e103fd225', 'Age': 66, 'Income': 47996, 'LoanAmount': 80890, 'CreditScore': 565, 'MonthsEmployed': 251, 'NumCreditLines': 9, 'InterestRate': 21.12, 'LoanTerm': 60, 'DTIRatio': 0.43, 'Education': 'Master', 'EmploymentType': 'Self-employed', 'MaritalStatus': 'Divorced', 'HasMortgage': 'No', 'HasDependents': 'No', 'LoanPurpose': 'Business', 'HasCoSigner': 'No'}\n",
      "--------------------------------------------------\n",
      "After\n",
      "{'LoanID': '368bafbc-73e1-46e1-ab17-2f3e103fd225', 'Age': 66, 'Income': 47996, 'LoanAmount': 80890, 'CreditScore': 565, 'MonthsEmployed': 251, 'NumCreditLines': 9, 'InterestRate': 21.12, 'LoanTerm': 60, 'DTIRatio': 0.43, 'Education': 2, 'EmploymentType': 2, 'MaritalStatus': 1, 'HasMortgage': 0, 'HasDependents': 0, 'LoanPurpose': 0, 'HasCoSigner': 0}\n",
      "Before\n",
      "{'LoanID': 'd9c2827d-26c2-4189-a8c5-5a9857eb0b68', 'Age': 37, 'Income': 137515, 'LoanAmount': 25274, 'CreditScore': 449, 'MonthsEmployed': 174, 'NumCreditLines': 3, 'InterestRate': 22.18, 'LoanTerm': 48, 'DTIRatio': 0.16, 'Education': 'High School', 'EmploymentType': 'Self-employed', 'MaritalStatus': 'Divorced', 'HasMortgage': 'Yes', 'HasDependents': 'No', 'LoanPurpose': 'Business', 'HasCoSigner': 'No'}\n",
      "--------------------------------------------------\n",
      "After\n",
      "{'LoanID': 'd9c2827d-26c2-4189-a8c5-5a9857eb0b68', 'Age': 37, 'Income': 137515, 'LoanAmount': 25274, 'CreditScore': 449, 'MonthsEmployed': 174, 'NumCreditLines': 3, 'InterestRate': 22.18, 'LoanTerm': 48, 'DTIRatio': 0.16, 'Education': 1, 'EmploymentType': 2, 'MaritalStatus': 1, 'HasMortgage': 1, 'HasDependents': 0, 'LoanPurpose': 0, 'HasCoSigner': 0}\n",
      "Before\n",
      "{'LoanID': '942c15b7-3b4a-4639-95ae-12eabb0eb99b', 'Age': 22, 'Income': 174767, 'LoanAmount': 71830, 'CreditScore': 503, 'MonthsEmployed': 377, 'NumCreditLines': 0, 'InterestRate': 7.35, 'LoanTerm': 24, 'DTIRatio': 0.3, 'Education': 'PhD', 'EmploymentType': 'Part-time', 'MaritalStatus': 'Married', 'HasMortgage': 'No', 'HasDependents': 'No', 'LoanPurpose': 'Education', 'HasCoSigner': 'Yes'}\n",
      "--------------------------------------------------\n",
      "After\n",
      "{'LoanID': '942c15b7-3b4a-4639-95ae-12eabb0eb99b', 'Age': 22, 'Income': 174767, 'LoanAmount': 71830, 'CreditScore': 503, 'MonthsEmployed': 377, 'NumCreditLines': 0, 'InterestRate': 7.35, 'LoanTerm': 24, 'DTIRatio': 0.3, 'Education': 3, 'EmploymentType': 0, 'MaritalStatus': 0, 'HasMortgage': 0, 'HasDependents': 0, 'LoanPurpose': 2, 'HasCoSigner': 1}\n",
      "Before\n",
      "{'LoanID': '7df5ac27-0ecd-4ad3-b28e-5bf2964e3ea6', 'Age': 47, 'Income': 138816, 'LoanAmount': 32159, 'CreditScore': 777, 'MonthsEmployed': 230, 'NumCreditLines': 6, 'InterestRate': 17.29, 'LoanTerm': 36, 'DTIRatio': 0.47, 'Education': 'PhD', 'EmploymentType': 'Part-time', 'MaritalStatus': 'Single', 'HasMortgage': 'No', 'HasDependents': 'No', 'LoanPurpose': 'Education', 'HasCoSigner': 'No'}\n",
      "--------------------------------------------------\n",
      "After\n",
      "{'LoanID': '7df5ac27-0ecd-4ad3-b28e-5bf2964e3ea6', 'Age': 47, 'Income': 138816, 'LoanAmount': 32159, 'CreditScore': 777, 'MonthsEmployed': 230, 'NumCreditLines': 6, 'InterestRate': 17.29, 'LoanTerm': 36, 'DTIRatio': 0.47, 'Education': 3, 'EmploymentType': 0, 'MaritalStatus': 2, 'HasMortgage': 0, 'HasDependents': 0, 'LoanPurpose': 2, 'HasCoSigner': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/26 23:45:38 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconsumer\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloan_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBefore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Scalable-Distributed-Systems/venv/lib/python3.11/site-packages/kafka/consumer/group.py:1193\u001b[0m, in \u001b[0;36mKafkaConsumer.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_v1()\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Scalable-Distributed-Systems/venv/lib/python3.11/site-packages/kafka/consumer/group.py:1201\u001b[0m, in \u001b[0;36mKafkaConsumer.next_v2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_generator_v2()\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   1203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Scalable-Distributed-Systems/venv/lib/python3.11/site-packages/kafka/consumer/group.py:1116\u001b[0m, in \u001b[0;36mKafkaConsumer._message_generator_v2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_message_generator_v2\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1115\u001b[0m     timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consumer_timeout \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mtime())\n\u001b[0;32m-> 1116\u001b[0m     record_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tp, records \u001b[38;5;129;01min\u001b[39;00m six\u001b[38;5;241m.\u001b[39miteritems(record_map):\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;66;03m# Generators are stateful, and it is possible that the tp / records\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m         \u001b[38;5;66;03m# here may become stale during iteration -- i.e., we seek to a\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m         \u001b[38;5;66;03m# different offset, pause consumption, or lose assignment.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m records:\n\u001b[1;32m   1122\u001b[0m             \u001b[38;5;66;03m# is_fetchable(tp) should handle assignment changes and offset\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m             \u001b[38;5;66;03m# resets; for all other changes (e.g., seeks) we'll rely on the\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m             \u001b[38;5;66;03m# outer function destroying the existing iterator/generator\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m             \u001b[38;5;66;03m# via self._iterator = None\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Scalable-Distributed-Systems/venv/lib/python3.11/site-packages/kafka/consumer/group.py:655\u001b[0m, in \u001b[0;36mKafkaConsumer.poll\u001b[0;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[1;32m    653\u001b[0m remaining \u001b[38;5;241m=\u001b[39m timeout_ms\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 655\u001b[0m     records \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_records\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_offsets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m records:\n\u001b[1;32m    657\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m records\n",
      "File \u001b[0;32m~/Desktop/Scalable-Distributed-Systems/venv/lib/python3.11/site-packages/kafka/consumer/group.py:702\u001b[0m, in \u001b[0;36mKafkaConsumer._poll_once\u001b[0;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpoll(timeout_ms\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    701\u001b[0m timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(timeout_ms, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinator\u001b[38;5;241m.\u001b[39mtime_to_next_poll() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m--> 702\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# after the long poll, we should check whether the group needs to rebalance\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;66;03m# prior to returning data so that the group can stabilize faster\u001b[39;00m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinator\u001b[38;5;241m.\u001b[39mneed_rejoin():\n",
      "File \u001b[0;32m~/Desktop/Scalable-Distributed-Systems/venv/lib/python3.11/site-packages/kafka/client_async.py:602\u001b[0m, in \u001b[0;36mKafkaClient.poll\u001b[0;34m(self, timeout_ms, future)\u001b[0m\n\u001b[1;32m    599\u001b[0m             timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(timeout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretry_backoff_ms\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    600\u001b[0m         timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, timeout)  \u001b[38;5;66;03m# avoid negative timeouts\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# called without the lock to avoid deadlock potential\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;66;03m# if handlers need to acquire locks\u001b[39;00m\n\u001b[1;32m    606\u001b[0m responses\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_pending_completed_requests())\n",
      "File \u001b[0;32m~/Desktop/Scalable-Distributed-Systems/venv/lib/python3.11/site-packages/kafka/client_async.py:634\u001b[0m, in \u001b[0;36mKafkaClient._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_register_send_sockets()\n\u001b[1;32m    633\u001b[0m start_select \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 634\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m end_select \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sensors:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/selectors.py:468\u001b[0m, in \u001b[0;36mEpollSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    466\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 468\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout, max_ev)\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for message in consumer:\n",
    "    loan_data = message.value\n",
    "    \n",
    "    print(\"Before\")\n",
    "    print(loan_data)\n",
    "    \n",
    "    indexed_data = indexing_data(loan_data= loan_data)\n",
    "    \n",
    "    print(\"-\"*50)\n",
    "    print(\"After\")\n",
    "    print(indexed_data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = message.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data ={'LoanID': '7df5ac27-0ecd-4ad3-b28e-5bf2964e3ea6',\n",
    " 'Age': 56,\n",
    " 'Income': 85994,\n",
    " 'LoanAmount': 50587,\n",
    " 'CreditScore': 520,\n",
    " 'MonthsEmployed': 80,\n",
    " 'NumCreditLines': 4,\n",
    " 'InterestRate': 15.23,\n",
    " 'LoanTerm': 36,\n",
    " 'DTIRatio': 0.44,\n",
    " 'Education': 0,\n",
    " 'EmploymentType': 3,\n",
    " 'MaritalStatus': 1,\n",
    " 'HasMortgage': 0,\n",
    " 'HasDependents': 0,\n",
    " 'LoanPurpose': 3,\n",
    " 'HasCoSigner': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df = spark.createDataFrame([loan_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'CreditScore',\n",
       " 'DTIRatio',\n",
       " 'Education',\n",
       " 'EmploymentType',\n",
       " 'HasCoSigner',\n",
       " 'HasDependents',\n",
       " 'HasMortgage',\n",
       " 'Income',\n",
       " 'InterestRate',\n",
       " 'LoanAmount',\n",
       " 'LoanID',\n",
       " 'LoanPurpose',\n",
       " 'LoanTerm',\n",
       " 'MaritalStatus',\n",
       " 'MonthsEmployed',\n",
       " 'NumCreditLines']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical features\n",
    "numerical_cols = [\n",
    "    \"Age\", \"Income\", \"LoanAmount\", \"CreditScore\", \"MonthsEmployed\",\n",
    "    \"NumCreditLines\", \"InterestRate\", \"LoanTerm\", \"DTIRatio\"\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=numerical_cols, outputCol=\"features\")\n",
    "loan_data_assembled = assembler.transform(data)\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
    "scaler_model = scaler.fit(loan_data_assembled)\n",
    "loan_data_scaled = scaler_model.transform(loan_data_assembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+--------+---------+--------------+-----------+-------------+-----------+------+------------+----------+--------------------+-----------+--------+-------------+--------------+--------------+--------------------+--------------------+\n",
      "|Age|CreditScore|DTIRatio|Education|EmploymentType|HasCoSigner|HasDependents|HasMortgage|Income|InterestRate|LoanAmount|              LoanID|LoanPurpose|LoanTerm|MaritalStatus|MonthsEmployed|NumCreditLines|            features|     scaled_features|\n",
      "+---+-----------+--------+---------+--------------+-----------+-------------+-----------+------+------------+----------+--------------------+-----------+--------+-------------+--------------+--------------+--------------------+--------------------+\n",
      "| 56|        520|    0.44|        0|             3|          0|            0|          0| 85994|       15.23|     50587|7df5ac27-0ecd-4ad...|          3|      36|            1|            80|             4|[56.0,85994.0,505...|[0.0,0.0,0.0,0.0,...|\n",
      "+---+-----------+--------+---------+--------------+-----------+-------------+-----------+------+------------+----------+--------------------+-----------+--------+-------------+--------------+--------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_data_scaled.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predictions = lr_model.transform(loan_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+--------+---------+--------------+-----------+-------------+-----------+------+------------+----------+--------------------+-----------+--------+-------------+--------------+--------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|Age|CreditScore|DTIRatio|Education|EmploymentType|HasCoSigner|HasDependents|HasMortgage|Income|InterestRate|LoanAmount|              LoanID|LoanPurpose|LoanTerm|MaritalStatus|MonthsEmployed|NumCreditLines|            features|     scaled_features|       rawPrediction|         probability|prediction|\n",
      "+---+-----------+--------+---------+--------------+-----------+-------------+-----------+------+------------+----------+--------------------+-----------+--------+-------------+--------------+--------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "| 56|        520|    0.44|        0|             3|          0|            0|          0| 85994|       15.23|     50587|7df5ac27-0ecd-4ad...|          3|      36|            1|            80|             4|[56.0,85994.0,505...|[0.0,0.0,0.0,0.0,...|[2.34103843489041...|[0.91221927372776...|       0.0|\n",
      "+---+-----------+--------+---------+--------------+-----------+-------------+-----------+------+------------+----------+--------------------+-----------+--------+-------------+--------------+--------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/27 00:04:47 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    }
   ],
   "source": [
    "lr_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
