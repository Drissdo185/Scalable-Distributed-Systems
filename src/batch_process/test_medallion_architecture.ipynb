{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data will go to Bronze layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to minio cline\n",
    "def get_minio_client():\n",
    "    client = Minio(\n",
    "        \"localhost:9000\",\n",
    "        access_key = os.getenv(\"MINIO_USERNAME\"),\n",
    "        secret_key = os.getenv(\"MINIO_PASSWORD\"),\n",
    "        secure = False\n",
    "    )\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(bucket_name, file_path):\n",
    "    try:\n",
    "        client = get_minio_client()\n",
    "\n",
    "        # Check if the bucket exists, if not, create it\n",
    "        if not client.bucket_exists(bucket_name):\n",
    "            print(f\"Bucket '{bucket_name}' does not exist. Creating it now.\")\n",
    "            client.make_bucket(bucket_name)\n",
    "\n",
    "        # Ensure the file path is valid\n",
    "        if not os.path.isfile(file_path):\n",
    "            print(f\"The file path '{file_path}' does not exist or is not a file.\")\n",
    "            return\n",
    "\n",
    "        # Extract the file name from the file path\n",
    "        file_name = os.path.basename(file_path)\n",
    "\n",
    "        # Upload the file to the specified bucket\n",
    "        client.fput_object(bucket_name, file_name, file_path)\n",
    "        print(f\"File '{file_name}' uploaded successfully to bucket '{bucket_name}'.\")\n",
    "\n",
    "    except S3Error as e:\n",
    "        print(f\"S3 Error occurred: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload raw data to bronze bucket\n",
    "\n",
    "# upload_file(\"bronze\", \"/home/drissdo/Desktop/Scalable-Distributed-Systems/data/Loan_default.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/27 00:00:30 WARN Utils: Your hostname, dtdat resolves to a loopback address: 127.0.1.1; using 192.168.2.12 instead (on interface wlp0s20f3)\n",
      "24/12/27 00:00:30 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "24/12/27 00:00:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/27 00:00:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, mean\n",
    "\n",
    "# Run full cores\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LoanDefaultPrediction\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"admin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"admin123\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://localhost:9000\")\\\n",
    "    .config(\"spark.jars\", \"/home/drissdo/Desktop/Scalable-Distributed-Systems/src/jars/aws-java-sdk-bundle-1.11.901.jar, /home/drissdo/Desktop/Scalable-Distributed-Systems/src/jars/hadoop-aws-3.3.1.jar\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+--------------+-------------+-----------+-------------+-----------+-----------+-------+\n",
      "|    LoanID|Age|Income|LoanAmount|CreditScore|MonthsEmployed|NumCreditLines|InterestRate|LoanTerm|DTIRatio|  Education|EmploymentType|MaritalStatus|HasMortgage|HasDependents|LoanPurpose|HasCoSigner|Default|\n",
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+--------------+-------------+-----------+-------------+-----------+-----------+-------+\n",
      "|I38PQUQS96| 56| 85994|     50587|        520|            80|             4|       15.23|      36|    0.44| Bachelor's|     Full-time|     Divorced|        Yes|          Yes|      Other|        Yes|      0|\n",
      "|HPSK72WA7R| 69| 50432|    124440|        458|            15|             1|        4.81|      60|    0.68|   Master's|     Full-time|      Married|         No|           No|      Other|        Yes|      0|\n",
      "|C1OZ6DPJ8Y| 46| 84208|    129188|        451|            26|             3|       21.17|      24|    0.31|   Master's|    Unemployed|     Divorced|        Yes|          Yes|       Auto|         No|      1|\n",
      "|V2KKSFM3UN| 32| 31713|     44799|        743|             0|             3|        7.07|      24|    0.23|High School|     Full-time|      Married|         No|           No|   Business|         No|      0|\n",
      "|EY08JDHTZP| 60| 20437|      9139|        633|             8|             4|        6.51|      48|    0.73| Bachelor's|    Unemployed|     Divorced|         No|          Yes|       Auto|         No|      0|\n",
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+--------------+-------------+-----------+-------------+-----------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/drissdo/Desktop/Scalable-Distributed-Systems/data/Loan_default.csv\"\n",
    "\n",
    "\n",
    "loan_data = spark.read.csv(data_path, inferSchema=True, header=True)\n",
    "\n",
    "# Display the first 5 rows\n",
    "loan_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LoanID',\n",
       " 'Age',\n",
       " 'Income',\n",
       " 'LoanAmount',\n",
       " 'CreditScore',\n",
       " 'MonthsEmployed',\n",
       " 'NumCreditLines',\n",
       " 'InterestRate',\n",
       " 'LoanTerm',\n",
       " 'DTIRatio',\n",
       " 'Education',\n",
       " 'EmploymentType',\n",
       " 'MaritalStatus',\n",
       " 'HasMortgage',\n",
       " 'HasDependents',\n",
       " 'LoanPurpose',\n",
       " 'HasCoSigner',\n",
       " 'Default']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LoanID: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Income: integer (nullable = true)\n",
      " |-- LoanAmount: integer (nullable = true)\n",
      " |-- CreditScore: integer (nullable = true)\n",
      " |-- MonthsEmployed: integer (nullable = true)\n",
      " |-- NumCreditLines: integer (nullable = true)\n",
      " |-- InterestRate: double (nullable = true)\n",
      " |-- LoanTerm: integer (nullable = true)\n",
      " |-- DTIRatio: double (nullable = true)\n",
      " |-- Education: string (nullable = true)\n",
      " |-- EmploymentType: string (nullable = true)\n",
      " |-- MaritalStatus: string (nullable = true)\n",
      " |-- HasMortgage: string (nullable = true)\n",
      " |-- HasDependents: string (nullable = true)\n",
      " |-- LoanPurpose: string (nullable = true)\n",
      " |-- HasCoSigner: string (nullable = true)\n",
      " |-- Default: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer, StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Data dont have missing value\n",
    "# imputer = Imputer(\n",
    "#     inputCols=[\"Income\", \"MonthsEmployed\", \"NumCreditLines\", \"InterestRate\", \"LoanTerm\", \"DTIRatio\"],\n",
    "#     outputCols=[\"Income_filled\", \"MonthsEmployed_filled\", \"NumCreditLines_filled\", \"InterestRate_filled\", \"LoanTerm_filled\", \"DTIRatio_filled\"]\n",
    "# )\n",
    "# loan_data_imputed = imputer.fit(loan_data).transform(loan_data)\n",
    "\n",
    "string_indexers = [\n",
    "    StringIndexer(inputCol=\"Education\", outputCol=\"Education_index\"),\n",
    "    StringIndexer(inputCol=\"EmploymentType\", outputCol=\"EmploymentType_index\"),\n",
    "    StringIndexer(inputCol=\"MaritalStatus\", outputCol=\"MaritalStatus_index\"),\n",
    "    StringIndexer(inputCol=\"HasMortgage\", outputCol=\"HasMortgage_index\"),\n",
    "    StringIndexer(inputCol=\"HasDependents\", outputCol=\"HasDependents_index\"),\n",
    "    StringIndexer(inputCol=\"LoanPurpose\", outputCol=\"LoanPurpose_index\"),\n",
    "    StringIndexer(inputCol=\"HasCoSigner\", outputCol=\"HasCoSigner_index\")\n",
    "]\n",
    "\n",
    "pipeline_indexers = Pipeline(stages=string_indexers)\n",
    "loan_data_indexed = pipeline_indexers.fit(loan_data).transform(loan_data)\n",
    "\n",
    "loan_data_indexed = loan_data_indexed.select(['LoanID',\n",
    " 'Age',\n",
    " 'Income',\n",
    " 'LoanAmount',\n",
    " 'CreditScore',\n",
    " 'MonthsEmployed',\n",
    " 'NumCreditLines',\n",
    " 'InterestRate',\n",
    " 'LoanTerm',\n",
    " 'DTIRatio',\n",
    " 'LoanPurpose',\n",
    " 'Default',\n",
    " 'Education_index',\n",
    " 'EmploymentType_index',\n",
    " 'MaritalStatus_index',\n",
    " 'HasMortgage_index',\n",
    " 'HasDependents_index',\n",
    " 'LoanPurpose_index',\n",
    " 'HasCoSigner_index'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+--------------+-------------+-----------+-------------+-----------+-----------+-------+\n",
      "|    LoanID|Age|Income|LoanAmount|CreditScore|MonthsEmployed|NumCreditLines|InterestRate|LoanTerm|DTIRatio|  Education|EmploymentType|MaritalStatus|HasMortgage|HasDependents|LoanPurpose|HasCoSigner|Default|\n",
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+--------------+-------------+-----------+-------------+-----------+-----------+-------+\n",
      "|I38PQUQS96| 56| 85994|     50587|        520|            80|             4|       15.23|      36|    0.44| Bachelor's|     Full-time|     Divorced|        Yes|          Yes|      Other|        Yes|      0|\n",
      "|HPSK72WA7R| 69| 50432|    124440|        458|            15|             1|        4.81|      60|    0.68|   Master's|     Full-time|      Married|         No|           No|      Other|        Yes|      0|\n",
      "|C1OZ6DPJ8Y| 46| 84208|    129188|        451|            26|             3|       21.17|      24|    0.31|   Master's|    Unemployed|     Divorced|        Yes|          Yes|       Auto|         No|      1|\n",
      "|V2KKSFM3UN| 32| 31713|     44799|        743|             0|             3|        7.07|      24|    0.23|High School|     Full-time|      Married|         No|           No|   Business|         No|      0|\n",
      "|EY08JDHTZP| 60| 20437|      9139|        633|             8|             4|        6.51|      48|    0.73| Bachelor's|    Unemployed|     Divorced|         No|          Yes|       Auto|         No|      0|\n",
      "|A9S62RQ7US| 25| 90298|     90448|        720|            18|             2|       22.72|      24|     0.1|High School|    Unemployed|       Single|        Yes|           No|   Business|        Yes|      1|\n",
      "|H8GXPAOS71| 38|111188|    177025|        429|            80|             1|       19.11|      12|    0.16| Bachelor's|    Unemployed|       Single|        Yes|           No|       Home|        Yes|      0|\n",
      "|0HGZQKJ36W| 56|126802|    155511|        531|            67|             4|        8.15|      60|    0.43|        PhD|     Full-time|      Married|         No|           No|       Home|        Yes|      0|\n",
      "|1R0N3LGNRJ| 36| 42053|     92357|        827|            83|             1|       23.94|      48|     0.2| Bachelor's| Self-employed|     Divorced|        Yes|           No|  Education|         No|      1|\n",
      "|CM9L1GTT2P| 40|132784|    228510|        480|           114|             4|        9.09|      48|    0.33|High School| Self-employed|      Married|        Yes|           No|      Other|        Yes|      0|\n",
      "|IA35XVH6ZO| 28|140466|    163781|        652|            94|             2|        9.08|      48|    0.23|High School|    Unemployed|      Married|         No|           No|  Education|         No|      0|\n",
      "|Y8UETC3LSG| 28|149227|    139759|        375|            56|             3|        5.84|      36|     0.8|        PhD|     Full-time|     Divorced|         No|           No|  Education|        Yes|      1|\n",
      "|RM6QSRHIYP| 41| 23265|     63527|        829|            87|             4|        9.73|      60|    0.45|   Master's|     Full-time|     Divorced|        Yes|           No|       Auto|        Yes|      0|\n",
      "|GX5YQOGROM| 53|117550|     95744|        395|           112|             4|        3.58|      24|    0.73|High School|    Unemployed|       Single|         No|           No|       Auto|        Yes|      0|\n",
      "|X0BVPZLDC0| 57|139699|     88143|        635|           112|             4|        5.63|      48|     0.2|   Master's|     Part-time|     Divorced|         No|           No|       Home|         No|      0|\n",
      "|O5DM5MPPNA| 41| 74064|    230883|        432|            31|             2|         5.0|      60|    0.89|   Master's|    Unemployed|      Married|        Yes|           No|       Auto|         No|      0|\n",
      "|ZDDRGVTEXS| 20|119704|     25697|        313|            49|             1|        9.63|      24|    0.28|        PhD|    Unemployed|       Single|        Yes|           No|       Home|         No|      0|\n",
      "|9V0FJW7QPB| 39| 33015|     10889|        811|           106|             2|       13.56|      60|    0.66|   Master's| Self-employed|       Single|        Yes|           No|      Other|         No|      0|\n",
      "|O1IKKLC69B| 19| 40718|     78515|        319|           119|             2|        14.0|      24|    0.17| Bachelor's| Self-employed|     Divorced|        Yes|           No|  Education|         No|      1|\n",
      "|F7487UU2BF| 41|123419|    161146|        376|            65|             4|       16.96|      60|    0.39|High School| Self-employed|       Single|        Yes|           No|      Other|        Yes|      0|\n",
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+--------------+-------------+-----------+-------------+-----------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+-------+---------------+--------------------+-------------------+-----------------+-------------------+-----------------+-----------------+\n",
      "|    LoanID|Age|Income|LoanAmount|CreditScore|MonthsEmployed|NumCreditLines|InterestRate|LoanTerm|DTIRatio|LoanPurpose|Default|Education_index|EmploymentType_index|MaritalStatus_index|HasMortgage_index|HasDependents_index|LoanPurpose_index|HasCoSigner_index|\n",
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+-------+---------------+--------------------+-------------------+-----------------+-------------------+-----------------+-----------------+\n",
      "|I38PQUQS96| 56| 85994|     50587|        520|            80|             4|       15.23|      36|    0.44|      Other|      0|            0.0|                 3.0|                1.0|              0.0|                0.0|              3.0|              0.0|\n",
      "|HPSK72WA7R| 69| 50432|    124440|        458|            15|             1|        4.81|      60|    0.68|      Other|      0|            2.0|                 3.0|                0.0|              1.0|                1.0|              3.0|              0.0|\n",
      "|C1OZ6DPJ8Y| 46| 84208|    129188|        451|            26|             3|       21.17|      24|    0.31|       Auto|      1|            2.0|                 1.0|                1.0|              0.0|                0.0|              4.0|              1.0|\n",
      "|V2KKSFM3UN| 32| 31713|     44799|        743|             0|             3|        7.07|      24|    0.23|   Business|      0|            1.0|                 3.0|                0.0|              1.0|                1.0|              0.0|              1.0|\n",
      "|EY08JDHTZP| 60| 20437|      9139|        633|             8|             4|        6.51|      48|    0.73|       Auto|      0|            0.0|                 1.0|                1.0|              1.0|                0.0|              4.0|              1.0|\n",
      "|A9S62RQ7US| 25| 90298|     90448|        720|            18|             2|       22.72|      24|     0.1|   Business|      1|            1.0|                 1.0|                2.0|              0.0|                1.0|              0.0|              0.0|\n",
      "|H8GXPAOS71| 38|111188|    177025|        429|            80|             1|       19.11|      12|    0.16|       Home|      0|            0.0|                 1.0|                2.0|              0.0|                1.0|              1.0|              0.0|\n",
      "|0HGZQKJ36W| 56|126802|    155511|        531|            67|             4|        8.15|      60|    0.43|       Home|      0|            3.0|                 3.0|                0.0|              1.0|                1.0|              1.0|              0.0|\n",
      "|1R0N3LGNRJ| 36| 42053|     92357|        827|            83|             1|       23.94|      48|     0.2|  Education|      1|            0.0|                 2.0|                1.0|              0.0|                1.0|              2.0|              1.0|\n",
      "|CM9L1GTT2P| 40|132784|    228510|        480|           114|             4|        9.09|      48|    0.33|      Other|      0|            1.0|                 2.0|                0.0|              0.0|                1.0|              3.0|              0.0|\n",
      "|IA35XVH6ZO| 28|140466|    163781|        652|            94|             2|        9.08|      48|    0.23|  Education|      0|            1.0|                 1.0|                0.0|              1.0|                1.0|              2.0|              1.0|\n",
      "|Y8UETC3LSG| 28|149227|    139759|        375|            56|             3|        5.84|      36|     0.8|  Education|      1|            3.0|                 3.0|                1.0|              1.0|                1.0|              2.0|              0.0|\n",
      "|RM6QSRHIYP| 41| 23265|     63527|        829|            87|             4|        9.73|      60|    0.45|       Auto|      0|            2.0|                 3.0|                1.0|              0.0|                1.0|              4.0|              0.0|\n",
      "|GX5YQOGROM| 53|117550|     95744|        395|           112|             4|        3.58|      24|    0.73|       Auto|      0|            1.0|                 1.0|                2.0|              1.0|                1.0|              4.0|              0.0|\n",
      "|X0BVPZLDC0| 57|139699|     88143|        635|           112|             4|        5.63|      48|     0.2|       Home|      0|            2.0|                 0.0|                1.0|              1.0|                1.0|              1.0|              1.0|\n",
      "|O5DM5MPPNA| 41| 74064|    230883|        432|            31|             2|         5.0|      60|    0.89|       Auto|      0|            2.0|                 1.0|                0.0|              0.0|                1.0|              4.0|              1.0|\n",
      "|ZDDRGVTEXS| 20|119704|     25697|        313|            49|             1|        9.63|      24|    0.28|       Home|      0|            3.0|                 1.0|                2.0|              0.0|                1.0|              1.0|              1.0|\n",
      "|9V0FJW7QPB| 39| 33015|     10889|        811|           106|             2|       13.56|      60|    0.66|      Other|      0|            2.0|                 2.0|                2.0|              0.0|                1.0|              3.0|              1.0|\n",
      "|O1IKKLC69B| 19| 40718|     78515|        319|           119|             2|        14.0|      24|    0.17|  Education|      1|            0.0|                 2.0|                1.0|              0.0|                1.0|              2.0|              1.0|\n",
      "|F7487UU2BF| 41|123419|    161146|        376|            65|             4|       16.96|      60|    0.39|      Other|      0|            1.0|                 2.0|                2.0|              0.0|                1.0|              3.0|              0.0|\n",
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+-------+---------------+--------------------+-------------------+-----------------+-------------------+-----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_data_indexed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Normalize numerical features\n",
    "numerical_cols = [\n",
    "    \"Age\", \"Income\", \"LoanAmount\", \"CreditScore\", \"MonthsEmployed\",\n",
    "    \"NumCreditLines\", \"InterestRate\", \"LoanTerm\", \"DTIRatio\"\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=numerical_cols, outputCol=\"features\")\n",
    "loan_data_assembled = assembler.transform(loan_data_indexed)\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
    "scaler_model = scaler.fit(loan_data_assembled)\n",
    "loan_data_scaled = scaler_model.transform(loan_data_assembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+-------+---------------+--------------------+-------------------+-----------------+-------------------+-----------------+-----------------+--------------------+--------------------+\n",
      "|    LoanID|Age|Income|LoanAmount|CreditScore|MonthsEmployed|NumCreditLines|InterestRate|LoanTerm|DTIRatio|LoanPurpose|Default|Education_index|EmploymentType_index|MaritalStatus_index|HasMortgage_index|HasDependents_index|LoanPurpose_index|HasCoSigner_index|            features|     scaled_features|\n",
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+-------+---------------+--------------------+-------------------+-----------------+-------------------+-----------------+-----------------+--------------------+--------------------+\n",
      "|I38PQUQS96| 56| 85994|     50587|        520|            80|             4|       15.23|      36|    0.44|      Other|      0|            0.0|                 3.0|                1.0|              0.0|                0.0|              3.0|              0.0|[56.0,85994.0,505...|[0.83398787561710...|\n",
      "|HPSK72WA7R| 69| 50432|    124440|        458|            15|             1|        4.81|      60|    0.68|      Other|      0|            2.0|                 3.0|                0.0|              1.0|                1.0|              3.0|              0.0|[69.0,50432.0,124...|[1.70121775497492...|\n",
      "|C1OZ6DPJ8Y| 46| 84208|    129188|        451|            26|             3|       21.17|      24|    0.31|       Auto|      1|            2.0|                 1.0|                1.0|              0.0|                0.0|              4.0|              1.0|[46.0,84208.0,129...|[0.16688796841878...|\n",
      "|V2KKSFM3UN| 32| 31713|     44799|        743|             0|             3|        7.07|      24|    0.23|   Business|      0|            1.0|                 3.0|                0.0|              1.0|                1.0|              0.0|              1.0|[32.0,31713.0,447...|[-0.7670519016588...|\n",
      "|EY08JDHTZP| 60| 20437|      9139|        633|             8|             4|        6.51|      48|    0.73|       Auto|      0|            0.0|                 1.0|                1.0|              1.0|                0.0|              4.0|              1.0|[60.0,20437.0,913...|[1.10082783849643...|\n",
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+-------+---------------+--------------------+-------------------+-----------------+-------------------+-----------------+-----------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_data_scaled.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \n",
    "\n",
    "    string_indexers = [\n",
    "        StringIndexer(inputCol=\"Education\", outputCol=\"Education_index\"),\n",
    "        StringIndexer(inputCol=\"EmploymentType\", outputCol=\"EmploymentType_index\"),\n",
    "        StringIndexer(inputCol=\"MaritalStatus\", outputCol=\"MaritalStatus_index\"),\n",
    "        StringIndexer(inputCol=\"HasMortgage\", outputCol=\"HasMortgage_index\"),\n",
    "        StringIndexer(inputCol=\"HasDependents\", outputCol=\"HasDependents_index\"),\n",
    "        StringIndexer(inputCol=\"LoanPurpose\", outputCol=\"LoanPurpose_index\"),\n",
    "        StringIndexer(inputCol=\"HasCoSigner\", outputCol=\"HasCoSigner_index\")]\n",
    "    \n",
    "    pipeline_indexers = Pipeline(stages=string_indexers)\n",
    "    df_indexed = pipeline_indexers.fit(df).transform(df)\n",
    "\n",
    "\n",
    "    pipeline_encoders = Pipeline(stages=one_hot_encoders)\n",
    "    df_encoded = pipeline_encoders.fit(df_indexed).transform(df_indexed)\n",
    "\n",
    "    # Normalize numerical features\n",
    "    numerical_cols = [\n",
    "        \"Age\", \"Income_filled\", \"LoanAmount\", \"CreditScore\", \"MonthsEmployed_filled\",\n",
    "        \"NumCreditLines_filled\", \"InterestRate_filled\", \"LoanTerm_filled\", \"DTIRatio_filled\"\n",
    "    ]\n",
    "\n",
    "    assembler = VectorAssembler(inputCols=numerical_cols, outputCol=\"features\")\n",
    "    df_assembled = assembler.transform(df_encoded)\n",
    "\n",
    "    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
    "\n",
    "    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
    "    scaler_model = scaler.fit(df_assembled)\n",
    "    df_scaled = scaler_model.transform(df_assembled)\n",
    "\n",
    "    \n",
    "\n",
    "    return df_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'one_hot_encoders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloan_data\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m20\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 17\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     13\u001b[0m pipeline_indexers \u001b[38;5;241m=\u001b[39m Pipeline(stages\u001b[38;5;241m=\u001b[39mstring_indexers)\n\u001b[1;32m     14\u001b[0m df_indexed \u001b[38;5;241m=\u001b[39m pipeline_indexers\u001b[38;5;241m.\u001b[39mfit(df)\u001b[38;5;241m.\u001b[39mtransform(df)\n\u001b[0;32m---> 17\u001b[0m pipeline_encoders \u001b[38;5;241m=\u001b[39m Pipeline(stages\u001b[38;5;241m=\u001b[39m\u001b[43mone_hot_encoders\u001b[49m)\n\u001b[1;32m     18\u001b[0m df_encoded \u001b[38;5;241m=\u001b[39m pipeline_encoders\u001b[38;5;241m.\u001b[39mfit(df_indexed)\u001b[38;5;241m.\u001b[39mtransform(df_indexed)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Normalize numerical features\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'one_hot_encoders' is not defined"
     ]
    }
   ],
   "source": [
    "data = preprocess_data(loan_data).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mselect([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data = data.select([\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save data to sliver bucket\n",
    "silver_bucket_path = \"s3a://sliver/preprocessed_loan_data\"\n",
    "loan_data_scaled.repartition(1).write.parquet(silver_bucket_path,  mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, rand\n",
    "\n",
    "\n",
    "# loan_data_scaled = spark.read.parquet(silver_bucket_path)\n",
    "\n",
    "default_data = loan_data_scaled.filter(col(\"Default\") == 1)\n",
    "non_default_data = loan_data_scaled.filter(col(\"Default\") == 0)\n",
    "\n",
    "train_default, test_default = default_data.randomSplit([0.8, 0.2], seed=42)\n",
    "train_non_default, test_non_default = non_default_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "train_data = train_default.union(train_non_default)\n",
    "test_data = test_default.union(test_non_default)\n",
    "\n",
    "# Shuffle the data\n",
    "train_data = train_data.orderBy(rand(seed=42))\n",
    "test_data = test_data.orderBy(rand(seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LoanID',\n",
       " 'Age',\n",
       " 'Income',\n",
       " 'LoanAmount',\n",
       " 'CreditScore',\n",
       " 'MonthsEmployed',\n",
       " 'NumCreditLines',\n",
       " 'InterestRate',\n",
       " 'LoanTerm',\n",
       " 'DTIRatio',\n",
       " 'LoanPurpose',\n",
       " 'Default',\n",
       " 'Education_index',\n",
       " 'EmploymentType_index',\n",
       " 'MaritalStatus_index',\n",
       " 'HasMortgage_index',\n",
       " 'HasDependents_index',\n",
       " 'LoanPurpose_index',\n",
       " 'HasCoSigner_index',\n",
       " 'features',\n",
       " 'scaled_features']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:>                                                       (0 + 12) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[27.0,17846.0,199...|\n",
      "+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_data.select([\"features\"]).show(1, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 377:==========================================>             (9 + 3) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+-------+---------------+--------------------+-------------------+-----------------+-------------------+-----------------+-----------------+--------------------+--------------------+\n",
      "|    LoanID|Age|Income|LoanAmount|CreditScore|MonthsEmployed|NumCreditLines|InterestRate|LoanTerm|DTIRatio|LoanPurpose|Default|Education_index|EmploymentType_index|MaritalStatus_index|HasMortgage_index|HasDependents_index|LoanPurpose_index|HasCoSigner_index|            features|     scaled_features|\n",
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+-------+---------------+--------------------+-------------------+-----------------+-------------------+-----------------+-----------------+--------------------+--------------------+\n",
      "|34A3QK885V| 27| 17846|    199268|        530|            87|             4|        20.7|      48|    0.72|       Home|      1|            3.0|                 3.0|                2.0|              1.0|                0.0|              1.0|              0.0|[27.0,17846.0,199...|[-1.1006018552580...|\n",
      "|CHA1MSRIJ6| 55|109762|     91868|        720|           100|             1|        5.57|      36|    0.27|  Education|      0|            3.0|                 0.0|                2.0|              0.0|                1.0|              2.0|              1.0|[55.0,109762.0,91...|[0.76727788489727...|\n",
      "|44NZIPZAOJ| 59|104162|    111092|        542|           108|             1|       12.46|      36|    0.47|       Home|      0|            3.0|                 0.0|                0.0|              0.0|                1.0|              1.0|              0.0|[59.0,104162.0,11...|[1.03411784777660...|\n",
      "|DPE68UOI5R| 36| 46474|    202266|        602|            23|             1|        8.77|      12|    0.81|       Home|      0|            0.0|                 2.0|                0.0|              0.0|                0.0|              1.0|              0.0|[36.0,46474.0,202...|[-0.5002119387795...|\n",
      "|BE04G5KYN3| 25|109587|     84457|        709|           105|             2|       13.22|      48|    0.69|       Home|      0|            2.0|                 1.0|                0.0|              1.0|                0.0|              1.0|              1.0|[25.0,109587.0,84...|[-1.2340218366976...|\n",
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+-------+---------------+--------------------+-------------------+-----------------+-------------------+-----------------+-----------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_data.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.select([\"LoanID\", \"Default\",\"features\"])\n",
    "test_data = test_data.select([\"LoanID\",\"Default\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 193:===================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|    LoanID|     scaled_features|\n",
      "+----------+--------------------+\n",
      "|7YG865MCWP|[-0.2333719759002...|\n",
      "|BEHFNNEUT1|[-1.1673118459778...|\n",
      "|T6RFSXUUDJ|[0.63385790345760...|\n",
      "|J2BKQP9IU7|[1.70121775497492...|\n",
      "|XHZW2365P0|[-1.4341518088571...|\n",
      "+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/27 00:01:52 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "[Stage 87:==============>                                          (3 + 9) / 12]\r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"Default\", maxIter=10)\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "lr_predictions = lr_model.transform(test_data)\n",
    "\n",
    "# # Evaluate the model\n",
    "# evaluator = BinaryClassificationEvaluator(labelCol=\"Default\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "# roc_auc_lr = evaluator.evaluate(lr_predictions)\n",
    "# print(f\"Logistic Regression - ROC AUC: {roc_auc_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 89:==============================================>         (10 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+--------------------+--------------------+----------+\n",
      "|    LoanID|Default|            features|       rawPrediction|         probability|prediction|\n",
      "+----------+-------+--------------------+--------------------+--------------------+----------+\n",
      "|49JA5VPNKF|      0|[19.0,39227.0,137...|[-0.2742316600795...|[0.43186852506906...|       1.0|\n",
      "|L0W7T47R9F|      0|[25.0,34235.0,220...|[-0.1507953048443...|[0.46237244855771...|       1.0|\n",
      "|8O4MIYPA7X|      1|[18.0,27322.0,207...|[-0.0410463675929...|[0.48973984859024...|       1.0|\n",
      "|MLE308KIZ4|      0|[28.0,43782.0,245...|[-0.0131252881382...|[0.49671872507160...|       1.0|\n",
      "|IU3NEZMQ9V|      0|[18.0,15602.0,164...|[-0.1193613301508...|[0.47019504531081...|       1.0|\n",
      "|TGO4OJKEJ1|      1|[26.0,41254.0,199...|[-0.0219395143697...|[0.49451534140563...|       1.0|\n",
      "|5Y6PHO1KWV|      0|[20.0,40670.0,143...|[-0.0653847611123...|[0.48365963079106...|       1.0|\n",
      "|A1OOA2LRMM|      1|[20.0,37370.0,208...|[-0.2263149312151...|[0.44366152627558...|       1.0|\n",
      "|DXJDVYK8W3|      1|[30.0,36683.0,242...|[-0.0427663750789...|[0.48931003547624...|       1.0|\n",
      "|Y7CQN618HP|      0|[23.0,24122.0,172...|[-0.0250652309382...|[0.49373402032040...|       1.0|\n",
      "|CMJYN1D637|      1|[20.0,46504.0,211...|[-0.0523671575631...|[0.48691120161109...|       1.0|\n",
      "|L4Q9N28PLC|      0|[19.0,28946.0,140...|[-0.3626406069944...|[0.41032050007920...|       1.0|\n",
      "|B57XHUWWNR|      0|[28.0,27342.0,244...|[-0.5827221501885...|[0.35830646776568...|       1.0|\n",
      "|BGU9W9Z94E|      1|[19.0,22447.0,209...|[-0.1125178734425...|[0.47190017134160...|       1.0|\n",
      "|7GFEUS34Y9|      0|[18.0,38723.0,214...|[-0.1349107216202...|[0.46632338284332...|       1.0|\n",
      "|TZWTWABFY2|      1|[26.0,21564.0,201...|[-0.0983877372609...|[0.47542288832437...|       1.0|\n",
      "|LNP08MJ7DB|      0|[22.0,56797.0,240...|[-0.2169867264446...|[0.44596516346778...|       1.0|\n",
      "|663CN15UGE|      0|[27.0,46844.0,230...|[-0.4511644341653...|[0.38908394708919...|       1.0|\n",
      "|8LSNKBWKF0|      0|[30.0,57774.0,222...|[-0.1174601174918...|[0.47066868625767...|       1.0|\n",
      "|Z4PXW3VTLP|      1|[19.0,39840.0,146...|[-0.5585555317969...|[0.36388174761899...|       1.0|\n",
      "+----------+-------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr_predictions_filtered = lr_predictions.filter(lr_predictions[\"prediction\"] == \"1\")\n",
    "print(lr_predictions_filtered.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|    LoanID|prediction|\n",
      "+----------+----------+\n",
      "|34A3QK885V|       0.0|\n",
      "|CHA1MSRIJ6|       0.0|\n",
      "|44NZIPZAOJ|       0.0|\n",
      "|DPE68UOI5R|       0.0|\n",
      "|BE04G5KYN3|       0.0|\n",
      "|D3NB8FM4O6|       0.0|\n",
      "|KJE40OMKWC|       0.0|\n",
      "|YPTUERR6Q6|       0.0|\n",
      "|1JDM6KSG9C|       0.0|\n",
      "|O4Z9BAWKIP|       0.0|\n",
      "|JWXJ2NP61G|       0.0|\n",
      "|JEFJN3BIUK|       0.0|\n",
      "|SR6GZVK6ZY|       0.0|\n",
      "|C383BGP0P3|       0.0|\n",
      "|05GK5TFA8V|       0.0|\n",
      "|A8AGYE8IN5|       0.0|\n",
      "|90ONLFQD7S|       0.0|\n",
      "|XW7FE0HOUO|       0.0|\n",
      "|TQ7YKS3BQH|       0.0|\n",
      "|NVUTOK3O3X|       0.0|\n",
      "+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Result: None\n"
     ]
    }
   ],
   "source": [
    "print(\"Result:\", lr_predictions.select(\"LoanID\", \"prediction\").show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"Default\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy_lr = accuracy_evaluator.evaluate(lr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8869761951603384\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path /home/drissdo/Desktop/Scalable-Distributed-Systems/ML/model already exists. Consider removing it or choosing a new path.\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "model_path = \"/home/drissdo/Desktop/Scalable-Distributed-Systems/ML/model\"\n",
    "\n",
    "\n",
    "import os\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Path {model_path} already exists. Consider removing it or choosing a new path.\")\n",
    "\n",
    "# Save the model\n",
    "lr_model.write().overwrite().save(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - ROC AUC: 0.7336530388666921\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "# Load the saved model\n",
    "loadedModel = LogisticRegressionModel.load(model_path)\n",
    "\n",
    "# Verify by making predictions using the loaded model\n",
    "lr_predictions = loadedModel.transform(test_data)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"Default\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "roc_auc_lr = evaluator.evaluate(lr_predictions)\n",
    "print(f\"Logistic Regression - ROC AUC: {roc_auc_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 188:===================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - ROC AUC: 0.4210816058940954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(featuresCol=\"scaled_features\", labelCol=\"Default\", maxDepth=10)\n",
    "dt_model = dt.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "dt_predictions = dt_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "roc_auc_dt = evaluator.evaluate(dt_predictions)\n",
    "print(f\"Decision Tree - ROC AUC: {roc_auc_dt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 243:===================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - ROC AUC: 0.7071944814368916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol=\"scaled_features\", labelCol=\"Default\", numTrees=100, maxDepth=5)\n",
    "rf_model = rf.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "rf_predictions = rf_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "roc_auc_rf = evaluator.evaluate(rf_predictions)\n",
    "print(f\"Random Forest - ROC AUC: {roc_auc_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient-Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 424:===================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient-Boosted Trees - ROC AUC: 0.7311417017458507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "gbt = GBTClassifier(featuresCol=\"scaled_features\", labelCol=\"Default\", maxIter=10, maxDepth=5)\n",
    "gbt_model = gbt.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "gbt_predictions = gbt_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "roc_auc_gbt = evaluator.evaluate(gbt_predictions)\n",
    "print(f\"Gradient-Boosted Trees - ROC AUC: {roc_auc_gbt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy: 0.8850444687158683, Precision: 0.8498232051102164, Recall: 0.8850444687158684, F1 Score: 0.8354146891676907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Accuracy: 0.8822554220627243, Precision: 0.8370298576990229, Recall: 0.8822554220627243, F1 Score: 0.841067195133172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Accuracy: 0.8844008425651427, Precision: 0.7821648503299344, Recall: 0.8844008425651427, F1 Score: 0.8301469970319177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 532:===================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient-Boosted Trees - Accuracy: 0.8852980184116087, Precision: 0.8498310312720517, Recall: 0.8852980184116087, F1 Score: 0.8382626093184488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Define evaluators\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"Default\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"Default\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"Default\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"Default\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "accuracy_lr = accuracy_evaluator.evaluate(lr_predictions)\n",
    "precision_lr = precision_evaluator.evaluate(lr_predictions)\n",
    "recall_lr = recall_evaluator.evaluate(lr_predictions)\n",
    "f1_lr = f1_evaluator.evaluate(lr_predictions)\n",
    "\n",
    "print(f\"Logistic Regression - Accuracy: {accuracy_lr}, Precision: {precision_lr}, Recall: {recall_lr}, F1 Score: {f1_lr}\")\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "accuracy_dt = accuracy_evaluator.evaluate(dt_predictions)\n",
    "precision_dt = precision_evaluator.evaluate(dt_predictions)\n",
    "recall_dt = recall_evaluator.evaluate(dt_predictions)\n",
    "f1_dt = f1_evaluator.evaluate(dt_predictions)\n",
    "\n",
    "print(f\"Decision Tree - Accuracy: {accuracy_dt}, Precision: {precision_dt}, Recall: {recall_dt}, F1 Score: {f1_dt}\")\n",
    "\n",
    "# Evaluate Random Forest\n",
    "accuracy_rf = accuracy_evaluator.evaluate(rf_predictions)\n",
    "precision_rf = precision_evaluator.evaluate(rf_predictions)\n",
    "recall_rf = recall_evaluator.evaluate(rf_predictions)\n",
    "f1_rf = f1_evaluator.evaluate(rf_predictions)\n",
    "\n",
    "print(f\"Random Forest - Accuracy: {accuracy_rf}, Precision: {precision_rf}, Recall: {recall_rf}, F1 Score: {f1_rf}\")\n",
    "\n",
    "# Evaluate Gradient-Boosted Trees\n",
    "accuracy_gbt = accuracy_evaluator.evaluate(gbt_predictions)\n",
    "precision_gbt = precision_evaluator.evaluate(gbt_predictions)\n",
    "recall_gbt = recall_evaluator.evaluate(gbt_predictions)\n",
    "f1_gbt = f1_evaluator.evaluate(gbt_predictions)\n",
    "\n",
    "print(f\"Gradient-Boosted Trees - Accuracy: {accuracy_gbt}, Precision: {precision_gbt}, Recall: {recall_gbt}, F1 Score: {f1_gbt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validated Model - ROC AUC: 0.7380937269287152\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# # Define parameter grid\n",
    "# paramGrid = ParamGridBuilder() \\\n",
    "#     .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "#     .addGrid(dt.maxDepth, [3, 5]) \\\n",
    "#     .addGrid(rf.numTrees, [50, 100]) \\\n",
    "#     .addGrid(gbt.maxIter, [5, 10]) \\\n",
    "#     .build()\n",
    "\n",
    "# # Define cross-validator\n",
    "# crossval = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "# # Fit the model\n",
    "# cvModel = crossval.fit(train_data)\n",
    "\n",
    "# # Make predictions\n",
    "# cv_predictions = cvModel.transform(test_data)\n",
    "\n",
    "# # Evaluate the model\n",
    "# roc_auc_cv = evaluator.evaluate(cv_predictions)\n",
    "# print(f\"Cross-Validated Model - ROC AUC: {roc_auc_cv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
