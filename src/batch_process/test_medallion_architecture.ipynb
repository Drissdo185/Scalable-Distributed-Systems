{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data will go to Bronze layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to minio cline\n",
    "def get_minio_client():\n",
    "    client = Minio(\n",
    "        \"localhost:9000\",\n",
    "        access_key = os.getenv(\"MINIO_USERNAME\"),\n",
    "        secret_key = os.getenv(\"MINIO_PASSWORD\"),\n",
    "        secure = False\n",
    "    )\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(bucket_name, file_path):\n",
    "    try:\n",
    "        client = get_minio_client()\n",
    "\n",
    "        # Check if the bucket exists, if not, create it\n",
    "        if not client.bucket_exists(bucket_name):\n",
    "            print(f\"Bucket '{bucket_name}' does not exist. Creating it now.\")\n",
    "            client.make_bucket(bucket_name)\n",
    "\n",
    "        # Ensure the file path is valid\n",
    "        if not os.path.isfile(file_path):\n",
    "            print(f\"The file path '{file_path}' does not exist or is not a file.\")\n",
    "            return\n",
    "\n",
    "        # Extract the file name from the file path\n",
    "        file_name = os.path.basename(file_path)\n",
    "\n",
    "        # Upload the file to the specified bucket\n",
    "        client.fput_object(bucket_name, file_name, file_path)\n",
    "        print(f\"File '{file_name}' uploaded successfully to bucket '{bucket_name}'.\")\n",
    "\n",
    "    except S3Error as e:\n",
    "        print(f\"S3 Error occurred: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload raw data to bronze bucket\n",
    "\n",
    "# upload_file(\"bronze\", \"/home/drissdo/Desktop/Scalable-Distributed-Systems/data/Loan_default.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, mean\n",
    "\n",
    "# Run full cores\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LoanDefaultPrediction\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"admin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"admin123\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://localhost:9000\")\\\n",
    "    .config(\"spark.jars\", \"/home/drissdo/Desktop/Scalable-Distributed-Systems/src/jars/aws-java-sdk-bundle-1.11.901.jar, /home/drissdo/Desktop/Scalable-Distributed-Systems/src/jars/hadoop-aws-3.3.1.jar\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+--------------+-------------+-----------+-------------+-----------+-----------+-------+\n",
      "|    LoanID|Age|Income|LoanAmount|CreditScore|MonthsEmployed|NumCreditLines|InterestRate|LoanTerm|DTIRatio|  Education|EmploymentType|MaritalStatus|HasMortgage|HasDependents|LoanPurpose|HasCoSigner|Default|\n",
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+--------------+-------------+-----------+-------------+-----------+-----------+-------+\n",
      "|I38PQUQS96| 56| 85994|     50587|        520|            80|             4|       15.23|      36|    0.44| Bachelor's|     Full-time|     Divorced|        Yes|          Yes|      Other|        Yes|      0|\n",
      "|HPSK72WA7R| 69| 50432|    124440|        458|            15|             1|        4.81|      60|    0.68|   Master's|     Full-time|      Married|         No|           No|      Other|        Yes|      0|\n",
      "|C1OZ6DPJ8Y| 46| 84208|    129188|        451|            26|             3|       21.17|      24|    0.31|   Master's|    Unemployed|     Divorced|        Yes|          Yes|       Auto|         No|      1|\n",
      "|V2KKSFM3UN| 32| 31713|     44799|        743|             0|             3|        7.07|      24|    0.23|High School|     Full-time|      Married|         No|           No|   Business|         No|      0|\n",
      "|EY08JDHTZP| 60| 20437|      9139|        633|             8|             4|        6.51|      48|    0.73| Bachelor's|    Unemployed|     Divorced|         No|          Yes|       Auto|         No|      0|\n",
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+--------------+-------------+-----------+-------------+-----------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"s3a://bronze/Loan_default.csv\"\n",
    "\n",
    "\n",
    "loan_data = spark.read.csv(data_path, inferSchema=True, header=True)\n",
    "\n",
    "# Display the first 5 rows\n",
    "loan_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LoanID',\n",
       " 'Age',\n",
       " 'Income',\n",
       " 'LoanAmount',\n",
       " 'CreditScore',\n",
       " 'MonthsEmployed',\n",
       " 'NumCreditLines',\n",
       " 'InterestRate',\n",
       " 'LoanTerm',\n",
       " 'DTIRatio',\n",
       " 'Education',\n",
       " 'EmploymentType',\n",
       " 'MaritalStatus',\n",
       " 'HasMortgage',\n",
       " 'HasDependents',\n",
       " 'LoanPurpose',\n",
       " 'HasCoSigner',\n",
       " 'Default']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LoanID: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Income: integer (nullable = true)\n",
      " |-- LoanAmount: integer (nullable = true)\n",
      " |-- CreditScore: integer (nullable = true)\n",
      " |-- MonthsEmployed: integer (nullable = true)\n",
      " |-- NumCreditLines: integer (nullable = true)\n",
      " |-- InterestRate: double (nullable = true)\n",
      " |-- LoanTerm: integer (nullable = true)\n",
      " |-- DTIRatio: double (nullable = true)\n",
      " |-- Education: string (nullable = true)\n",
      " |-- EmploymentType: string (nullable = true)\n",
      " |-- MaritalStatus: string (nullable = true)\n",
      " |-- HasMortgage: string (nullable = true)\n",
      " |-- HasDependents: string (nullable = true)\n",
      " |-- LoanPurpose: string (nullable = true)\n",
      " |-- HasCoSigner: string (nullable = true)\n",
      " |-- Default: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer, StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=[\"Income\", \"MonthsEmployed\", \"NumCreditLines\", \"InterestRate\", \"LoanTerm\", \"DTIRatio\"],\n",
    "    outputCols=[\"Income_filled\", \"MonthsEmployed_filled\", \"NumCreditLines_filled\", \"InterestRate_filled\", \"LoanTerm_filled\", \"DTIRatio_filled\"]\n",
    ")\n",
    "loan_data_imputed = imputer.fit(loan_data).transform(loan_data)\n",
    "\n",
    "string_indexers = [\n",
    "    StringIndexer(inputCol=\"Education\", outputCol=\"Education_index\"),\n",
    "    StringIndexer(inputCol=\"EmploymentType\", outputCol=\"EmploymentType_index\"),\n",
    "    StringIndexer(inputCol=\"MaritalStatus\", outputCol=\"MaritalStatus_index\"),\n",
    "    StringIndexer(inputCol=\"HasMortgage\", outputCol=\"HasMortgage_index\"),\n",
    "    StringIndexer(inputCol=\"HasDependents\", outputCol=\"HasDependents_index\"),\n",
    "    StringIndexer(inputCol=\"LoanPurpose\", outputCol=\"LoanPurpose_index\"),\n",
    "    StringIndexer(inputCol=\"HasCoSigner\", outputCol=\"HasCoSigner_index\")\n",
    "]\n",
    "\n",
    "pipeline_indexers = Pipeline(stages=string_indexers)\n",
    "loan_data_indexed = pipeline_indexers.fit(loan_data_imputed).transform(loan_data_imputed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# One-hot encode indexed columns\n",
    "one_hot_encoders = [\n",
    "    OneHotEncoder(inputCol=\"Education_index\", outputCol=\"Education_vec\"),\n",
    "    OneHotEncoder(inputCol=\"EmploymentType_index\", outputCol=\"EmploymentType_vec\"),\n",
    "    OneHotEncoder(inputCol=\"MaritalStatus_index\", outputCol=\"MaritalStatus_vec\"),\n",
    "    OneHotEncoder(inputCol=\"HasMortgage_index\", outputCol=\"HasMortgage_vec\"),\n",
    "    OneHotEncoder(inputCol=\"HasDependents_index\", outputCol=\"HasDependents_vec\"),\n",
    "    OneHotEncoder(inputCol=\"LoanPurpose_index\", outputCol=\"LoanPurpose_vec\"),\n",
    "    OneHotEncoder(inputCol=\"HasCoSigner_index\", outputCol=\"HasCoSigner_vec\")\n",
    "]\n",
    "\n",
    "pipeline_encoders = Pipeline(stages=one_hot_encoders)\n",
    "loan_data_encoded = pipeline_encoders.fit(loan_data_indexed).transform(loan_data_indexed)\n",
    "\n",
    "# Normalize numerical features\n",
    "numerical_cols = [\n",
    "    \"Age\", \"Income_filled\", \"LoanAmount\", \"CreditScore\", \"MonthsEmployed_filled\",\n",
    "    \"NumCreditLines_filled\", \"InterestRate_filled\", \"LoanTerm_filled\", \"DTIRatio_filled\"\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=numerical_cols, outputCol=\"features\")\n",
    "loan_data_assembled = assembler.transform(loan_data_encoded)\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
    "scaler_model = scaler.fit(loan_data_assembled)\n",
    "loan_data_scaled = scaler_model.transform(loan_data_assembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    imputer = Imputer(\n",
    "    inputCols=[\"Income\", \"MonthsEmployed\", \"NumCreditLines\", \"InterestRate\", \"LoanTerm\", \"DTIRatio\"],\n",
    "    outputCols=[\"Income_filled\", \"MonthsEmployed_filled\", \"NumCreditLines_filled\", \"InterestRate_filled\", \"LoanTerm_filled\", \"DTIRatio_filled\"]\n",
    ")\n",
    "    df_imputed = imputer.fit(df).transform(df)\n",
    "\n",
    "    string_indexers = [\n",
    "        StringIndexer(inputCol=\"Education\", outputCol=\"Education_index\"),\n",
    "        StringIndexer(inputCol=\"EmploymentType\", outputCol=\"EmploymentType_index\"),\n",
    "        StringIndexer(inputCol=\"MaritalStatus\", outputCol=\"MaritalStatus_index\"),\n",
    "        StringIndexer(inputCol=\"HasMortgage\", outputCol=\"HasMortgage_index\"),\n",
    "        StringIndexer(inputCol=\"HasDependents\", outputCol=\"HasDependents_index\"),\n",
    "        StringIndexer(inputCol=\"LoanPurpose\", outputCol=\"LoanPurpose_index\"),\n",
    "        StringIndexer(inputCol=\"HasCoSigner\", outputCol=\"HasCoSigner_index\")]\n",
    "    \n",
    "    pipeline_indexers = Pipeline(stages=string_indexers)\n",
    "    df_indexed = pipeline_indexers.fit(df_imputed).transform(df_imputed)\n",
    "\n",
    "\n",
    "    # scale data\n",
    "    one_hot_encoders = [\n",
    "    OneHotEncoder(inputCol=\"Education_index\", outputCol=\"Education_vec\"),\n",
    "    OneHotEncoder(inputCol=\"EmploymentType_index\", outputCol=\"EmploymentType_vec\"),\n",
    "    OneHotEncoder(inputCol=\"MaritalStatus_index\", outputCol=\"MaritalStatus_vec\"),\n",
    "    OneHotEncoder(inputCol=\"HasMortgage_index\", outputCol=\"HasMortgage_vec\"),\n",
    "    OneHotEncoder(inputCol=\"HasDependents_index\", outputCol=\"HasDependents_vec\"),\n",
    "    OneHotEncoder(inputCol=\"LoanPurpose_index\", outputCol=\"LoanPurpose_vec\"),\n",
    "    OneHotEncoder(inputCol=\"HasCoSigner_index\", outputCol=\"HasCoSigner_vec\")\n",
    "]\n",
    "\n",
    "    pipeline_encoders = Pipeline(stages=one_hot_encoders)\n",
    "    df_encoded = pipeline_encoders.fit(df_indexed).transform(df_indexed)\n",
    "\n",
    "    # Normalize numerical features\n",
    "    numerical_cols = [\n",
    "        \"Age\", \"Income_filled\", \"LoanAmount\", \"CreditScore\", \"MonthsEmployed_filled\",\n",
    "        \"NumCreditLines_filled\", \"InterestRate_filled\", \"LoanTerm_filled\", \"DTIRatio_filled\"\n",
    "    ]\n",
    "\n",
    "    assembler = VectorAssembler(inputCols=numerical_cols, outputCol=\"features\")\n",
    "    df_assembled = assembler.transform(df_encoded)\n",
    "\n",
    "    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
    "\n",
    "    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
    "    scaler_model = scaler.fit(df_assembled)\n",
    "    df_scaled = scaler_model.transform(df_assembled)\n",
    "\n",
    "    \n",
    "\n",
    "    return df_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/12 10:01:22 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+--------------+-------------+-----------+-------------+-----------+-----------+-------+-------------+---------------------+---------------------+-------------------+---------------+---------------+---------------+--------------------+-------------------+-----------------+-------------------+-----------------+-----------------+-------------+------------------+-----------------+---------------+-----------------+---------------+---------------+--------------------+--------------------+\n",
      "|    LoanID|Age|Income|LoanAmount|CreditScore|MonthsEmployed|NumCreditLines|InterestRate|LoanTerm|DTIRatio|  Education|EmploymentType|MaritalStatus|HasMortgage|HasDependents|LoanPurpose|HasCoSigner|Default|Income_filled|MonthsEmployed_filled|NumCreditLines_filled|InterestRate_filled|LoanTerm_filled|DTIRatio_filled|Education_index|EmploymentType_index|MaritalStatus_index|HasMortgage_index|HasDependents_index|LoanPurpose_index|HasCoSigner_index|Education_vec|EmploymentType_vec|MaritalStatus_vec|HasMortgage_vec|HasDependents_vec|LoanPurpose_vec|HasCoSigner_vec|            features|     scaled_features|\n",
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+--------------+-------------+-----------+-------------+-----------+-----------+-------+-------------+---------------------+---------------------+-------------------+---------------+---------------+---------------+--------------------+-------------------+-----------------+-------------------+-----------------+-----------------+-------------+------------------+-----------------+---------------+-----------------+---------------+---------------+--------------------+--------------------+\n",
      "|I38PQUQS96| 56| 85994|     50587|        520|            80|             4|       15.23|      36|    0.44| Bachelor's|     Full-time|     Divorced|        Yes|          Yes|      Other|        Yes|      0|        85994|                   80|                    4|              15.23|             36|           0.44|            0.0|                 3.0|                1.0|              0.0|                0.0|              3.0|              0.0|(3,[0],[1.0])|         (3,[],[])|    (2,[1],[1.0])|  (1,[0],[1.0])|    (1,[0],[1.0])|  (4,[3],[1.0])|  (1,[0],[1.0])|[56.0,85994.0,505...|[0.83398787561710...|\n",
      "|HPSK72WA7R| 69| 50432|    124440|        458|            15|             1|        4.81|      60|    0.68|   Master's|     Full-time|      Married|         No|           No|      Other|        Yes|      0|        50432|                   15|                    1|               4.81|             60|           0.68|            2.0|                 3.0|                0.0|              1.0|                1.0|              3.0|              0.0|(3,[2],[1.0])|         (3,[],[])|    (2,[0],[1.0])|      (1,[],[])|        (1,[],[])|  (4,[3],[1.0])|  (1,[0],[1.0])|[69.0,50432.0,124...|[1.70121775497492...|\n",
      "|C1OZ6DPJ8Y| 46| 84208|    129188|        451|            26|             3|       21.17|      24|    0.31|   Master's|    Unemployed|     Divorced|        Yes|          Yes|       Auto|         No|      1|        84208|                   26|                    3|              21.17|             24|           0.31|            2.0|                 1.0|                1.0|              0.0|                0.0|              4.0|              1.0|(3,[2],[1.0])|     (3,[1],[1.0])|    (2,[1],[1.0])|  (1,[0],[1.0])|    (1,[0],[1.0])|      (4,[],[])|      (1,[],[])|[46.0,84208.0,129...|[0.16688796841878...|\n",
      "|V2KKSFM3UN| 32| 31713|     44799|        743|             0|             3|        7.07|      24|    0.23|High School|     Full-time|      Married|         No|           No|   Business|         No|      0|        31713|                    0|                    3|               7.07|             24|           0.23|            1.0|                 3.0|                0.0|              1.0|                1.0|              0.0|              1.0|(3,[1],[1.0])|         (3,[],[])|    (2,[0],[1.0])|      (1,[],[])|        (1,[],[])|  (4,[0],[1.0])|      (1,[],[])|[32.0,31713.0,447...|[-0.7670519016588...|\n",
      "|EY08JDHTZP| 60| 20437|      9139|        633|             8|             4|        6.51|      48|    0.73| Bachelor's|    Unemployed|     Divorced|         No|          Yes|       Auto|         No|      0|        20437|                    8|                    4|               6.51|             48|           0.73|            0.0|                 1.0|                1.0|              1.0|                0.0|              4.0|              1.0|(3,[0],[1.0])|     (3,[1],[1.0])|    (2,[1],[1.0])|      (1,[],[])|    (1,[0],[1.0])|      (4,[],[])|      (1,[],[])|[60.0,20437.0,913...|[1.10082783849643...|\n",
      "|A9S62RQ7US| 25| 90298|     90448|        720|            18|             2|       22.72|      24|     0.1|High School|    Unemployed|       Single|        Yes|           No|   Business|        Yes|      1|        90298|                   18|                    2|              22.72|             24|            0.1|            1.0|                 1.0|                2.0|              0.0|                1.0|              0.0|              0.0|(3,[1],[1.0])|     (3,[1],[1.0])|        (2,[],[])|  (1,[0],[1.0])|        (1,[],[])|  (4,[0],[1.0])|  (1,[0],[1.0])|[25.0,90298.0,904...|[-1.2340218366976...|\n",
      "|H8GXPAOS71| 38|111188|    177025|        429|            80|             1|       19.11|      12|    0.16| Bachelor's|    Unemployed|       Single|        Yes|           No|       Home|        Yes|      0|       111188|                   80|                    1|              19.11|             12|           0.16|            0.0|                 1.0|                2.0|              0.0|                1.0|              1.0|              0.0|(3,[0],[1.0])|     (3,[1],[1.0])|        (2,[],[])|  (1,[0],[1.0])|        (1,[],[])|  (4,[1],[1.0])|  (1,[0],[1.0])|[38.0,111188.0,17...|[-0.3667919573398...|\n",
      "|0HGZQKJ36W| 56|126802|    155511|        531|            67|             4|        8.15|      60|    0.43|        PhD|     Full-time|      Married|         No|           No|       Home|        Yes|      0|       126802|                   67|                    4|               8.15|             60|           0.43|            3.0|                 3.0|                0.0|              1.0|                1.0|              1.0|              0.0|    (3,[],[])|         (3,[],[])|    (2,[0],[1.0])|      (1,[],[])|        (1,[],[])|  (4,[1],[1.0])|  (1,[0],[1.0])|[56.0,126802.0,15...|[0.83398787561710...|\n",
      "|1R0N3LGNRJ| 36| 42053|     92357|        827|            83|             1|       23.94|      48|     0.2| Bachelor's| Self-employed|     Divorced|        Yes|           No|  Education|         No|      1|        42053|                   83|                    1|              23.94|             48|            0.2|            0.0|                 2.0|                1.0|              0.0|                1.0|              2.0|              1.0|(3,[0],[1.0])|     (3,[2],[1.0])|    (2,[1],[1.0])|  (1,[0],[1.0])|        (1,[],[])|  (4,[2],[1.0])|      (1,[],[])|[36.0,42053.0,923...|[-0.5002119387795...|\n",
      "|CM9L1GTT2P| 40|132784|    228510|        480|           114|             4|        9.09|      48|    0.33|High School| Self-employed|      Married|        Yes|           No|      Other|        Yes|      0|       132784|                  114|                    4|               9.09|             48|           0.33|            1.0|                 2.0|                0.0|              0.0|                1.0|              3.0|              0.0|(3,[1],[1.0])|     (3,[2],[1.0])|    (2,[0],[1.0])|  (1,[0],[1.0])|        (1,[],[])|  (4,[3],[1.0])|  (1,[0],[1.0])|[40.0,132784.0,22...|[-0.2333719759002...|\n",
      "|IA35XVH6ZO| 28|140466|    163781|        652|            94|             2|        9.08|      48|    0.23|High School|    Unemployed|      Married|         No|           No|  Education|         No|      0|       140466|                   94|                    2|               9.08|             48|           0.23|            1.0|                 1.0|                0.0|              1.0|                1.0|              2.0|              1.0|(3,[1],[1.0])|     (3,[1],[1.0])|    (2,[0],[1.0])|      (1,[],[])|        (1,[],[])|  (4,[2],[1.0])|      (1,[],[])|[28.0,140466.0,16...|[-1.0338918645381...|\n",
      "|Y8UETC3LSG| 28|149227|    139759|        375|            56|             3|        5.84|      36|     0.8|        PhD|     Full-time|     Divorced|         No|           No|  Education|        Yes|      1|       149227|                   56|                    3|               5.84|             36|            0.8|            3.0|                 3.0|                1.0|              1.0|                1.0|              2.0|              0.0|    (3,[],[])|         (3,[],[])|    (2,[1],[1.0])|      (1,[],[])|        (1,[],[])|  (4,[2],[1.0])|  (1,[0],[1.0])|[28.0,149227.0,13...|[-1.0338918645381...|\n",
      "|RM6QSRHIYP| 41| 23265|     63527|        829|            87|             4|        9.73|      60|    0.45|   Master's|     Full-time|     Divorced|        Yes|           No|       Auto|        Yes|      0|        23265|                   87|                    4|               9.73|             60|           0.45|            2.0|                 3.0|                1.0|              0.0|                1.0|              4.0|              0.0|(3,[2],[1.0])|         (3,[],[])|    (2,[1],[1.0])|  (1,[0],[1.0])|        (1,[],[])|      (4,[],[])|  (1,[0],[1.0])|[41.0,23265.0,635...|[-0.1666619851803...|\n",
      "|GX5YQOGROM| 53|117550|     95744|        395|           112|             4|        3.58|      24|    0.73|High School|    Unemployed|       Single|         No|           No|       Auto|        Yes|      0|       117550|                  112|                    4|               3.58|             24|           0.73|            1.0|                 1.0|                2.0|              1.0|                1.0|              4.0|              0.0|(3,[1],[1.0])|     (3,[1],[1.0])|        (2,[],[])|      (1,[],[])|        (1,[],[])|      (4,[],[])|  (1,[0],[1.0])|[53.0,117550.0,95...|[0.63385790345760...|\n",
      "|X0BVPZLDC0| 57|139699|     88143|        635|           112|             4|        5.63|      48|     0.2|   Master's|     Part-time|     Divorced|         No|           No|       Home|         No|      0|       139699|                  112|                    4|               5.63|             48|            0.2|            2.0|                 0.0|                1.0|              1.0|                1.0|              1.0|              1.0|(3,[2],[1.0])|     (3,[0],[1.0])|    (2,[1],[1.0])|      (1,[],[])|        (1,[],[])|  (4,[1],[1.0])|      (1,[],[])|[57.0,139699.0,88...|[0.90069786633693...|\n",
      "|O5DM5MPPNA| 41| 74064|    230883|        432|            31|             2|         5.0|      60|    0.89|   Master's|    Unemployed|      Married|        Yes|           No|       Auto|         No|      0|        74064|                   31|                    2|                5.0|             60|           0.89|            2.0|                 1.0|                0.0|              0.0|                1.0|              4.0|              1.0|(3,[2],[1.0])|     (3,[1],[1.0])|    (2,[0],[1.0])|  (1,[0],[1.0])|        (1,[],[])|      (4,[],[])|      (1,[],[])|[41.0,74064.0,230...|[-0.1666619851803...|\n",
      "|ZDDRGVTEXS| 20|119704|     25697|        313|            49|             1|        9.63|      24|    0.28|        PhD|    Unemployed|       Single|        Yes|           No|       Home|         No|      0|       119704|                   49|                    1|               9.63|             24|           0.28|            3.0|                 1.0|                2.0|              0.0|                1.0|              1.0|              1.0|    (3,[],[])|     (3,[1],[1.0])|        (2,[],[])|  (1,[0],[1.0])|        (1,[],[])|  (4,[1],[1.0])|      (1,[],[])|[20.0,119704.0,25...|[-1.5675717902968...|\n",
      "|9V0FJW7QPB| 39| 33015|     10889|        811|           106|             2|       13.56|      60|    0.66|   Master's| Self-employed|       Single|        Yes|           No|      Other|         No|      0|        33015|                  106|                    2|              13.56|             60|           0.66|            2.0|                 2.0|                2.0|              0.0|                1.0|              3.0|              1.0|(3,[2],[1.0])|     (3,[2],[1.0])|        (2,[],[])|  (1,[0],[1.0])|        (1,[],[])|  (4,[3],[1.0])|      (1,[],[])|[39.0,33015.0,108...|[-0.3000819666200...|\n",
      "|O1IKKLC69B| 19| 40718|     78515|        319|           119|             2|        14.0|      24|    0.17| Bachelor's| Self-employed|     Divorced|        Yes|           No|  Education|         No|      1|        40718|                  119|                    2|               14.0|             24|           0.17|            0.0|                 2.0|                1.0|              0.0|                1.0|              2.0|              1.0|(3,[0],[1.0])|     (3,[2],[1.0])|    (2,[1],[1.0])|  (1,[0],[1.0])|        (1,[],[])|  (4,[2],[1.0])|      (1,[],[])|[19.0,40718.0,785...|[-1.6342817810166...|\n",
      "|F7487UU2BF| 41|123419|    161146|        376|            65|             4|       16.96|      60|    0.39|High School| Self-employed|       Single|        Yes|           No|      Other|        Yes|      0|       123419|                   65|                    4|              16.96|             60|           0.39|            1.0|                 2.0|                2.0|              0.0|                1.0|              3.0|              0.0|(3,[1],[1.0])|     (3,[2],[1.0])|        (2,[],[])|  (1,[0],[1.0])|        (1,[],[])|  (4,[3],[1.0])|  (1,[0],[1.0])|[41.0,123419.0,16...|[-0.1666619851803...|\n",
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+--------------+-------------+-----------+-------------+-----------+-----------+-------+-------------+---------------------+---------------------+-------------------+---------------+---------------+---------------+--------------------+-------------------+-----------------+-------------------+-----------------+-----------------+-------------+------------------+-----------------+---------------+-----------------+---------------+---------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocess_data(loan_data).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+--------------+-------------+-----------+-------------+-----------+-----------+-------+-------------+---------------------+---------------------+-------------------+---------------+---------------+---------------+--------------------+-------------------+-----------------+-------------------+-----------------+-----------------+-------------+------------------+-----------------+---------------+-----------------+---------------+---------------+--------------------+--------------------+\n",
      "|    LoanID|Age|Income|LoanAmount|CreditScore|MonthsEmployed|NumCreditLines|InterestRate|LoanTerm|DTIRatio|  Education|EmploymentType|MaritalStatus|HasMortgage|HasDependents|LoanPurpose|HasCoSigner|Default|Income_filled|MonthsEmployed_filled|NumCreditLines_filled|InterestRate_filled|LoanTerm_filled|DTIRatio_filled|Education_index|EmploymentType_index|MaritalStatus_index|HasMortgage_index|HasDependents_index|LoanPurpose_index|HasCoSigner_index|Education_vec|EmploymentType_vec|MaritalStatus_vec|HasMortgage_vec|HasDependents_vec|LoanPurpose_vec|HasCoSigner_vec|            features|     scaled_features|\n",
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+--------------+-------------+-----------+-------------+-----------+-----------+-------+-------------+---------------------+---------------------+-------------------+---------------+---------------+---------------+--------------------+-------------------+-----------------+-------------------+-----------------+-----------------+-------------+------------------+-----------------+---------------+-----------------+---------------+---------------+--------------------+--------------------+\n",
      "|I38PQUQS96| 56| 85994|     50587|        520|            80|             4|       15.23|      36|    0.44| Bachelor's|     Full-time|     Divorced|        Yes|          Yes|      Other|        Yes|      0|        85994|                   80|                    4|              15.23|             36|           0.44|            0.0|                 3.0|                1.0|              0.0|                0.0|              3.0|              0.0|(3,[0],[1.0])|         (3,[],[])|    (2,[1],[1.0])|  (1,[0],[1.0])|    (1,[0],[1.0])|  (4,[3],[1.0])|  (1,[0],[1.0])|[56.0,85994.0,505...|[0.83398787561710...|\n",
      "|HPSK72WA7R| 69| 50432|    124440|        458|            15|             1|        4.81|      60|    0.68|   Master's|     Full-time|      Married|         No|           No|      Other|        Yes|      0|        50432|                   15|                    1|               4.81|             60|           0.68|            2.0|                 3.0|                0.0|              1.0|                1.0|              3.0|              0.0|(3,[2],[1.0])|         (3,[],[])|    (2,[0],[1.0])|      (1,[],[])|        (1,[],[])|  (4,[3],[1.0])|  (1,[0],[1.0])|[69.0,50432.0,124...|[1.70121775497492...|\n",
      "|C1OZ6DPJ8Y| 46| 84208|    129188|        451|            26|             3|       21.17|      24|    0.31|   Master's|    Unemployed|     Divorced|        Yes|          Yes|       Auto|         No|      1|        84208|                   26|                    3|              21.17|             24|           0.31|            2.0|                 1.0|                1.0|              0.0|                0.0|              4.0|              1.0|(3,[2],[1.0])|     (3,[1],[1.0])|    (2,[1],[1.0])|  (1,[0],[1.0])|    (1,[0],[1.0])|      (4,[],[])|      (1,[],[])|[46.0,84208.0,129...|[0.16688796841878...|\n",
      "|V2KKSFM3UN| 32| 31713|     44799|        743|             0|             3|        7.07|      24|    0.23|High School|     Full-time|      Married|         No|           No|   Business|         No|      0|        31713|                    0|                    3|               7.07|             24|           0.23|            1.0|                 3.0|                0.0|              1.0|                1.0|              0.0|              1.0|(3,[1],[1.0])|         (3,[],[])|    (2,[0],[1.0])|      (1,[],[])|        (1,[],[])|  (4,[0],[1.0])|      (1,[],[])|[32.0,31713.0,447...|[-0.7670519016588...|\n",
      "|EY08JDHTZP| 60| 20437|      9139|        633|             8|             4|        6.51|      48|    0.73| Bachelor's|    Unemployed|     Divorced|         No|          Yes|       Auto|         No|      0|        20437|                    8|                    4|               6.51|             48|           0.73|            0.0|                 1.0|                1.0|              1.0|                0.0|              4.0|              1.0|(3,[0],[1.0])|     (3,[1],[1.0])|    (2,[1],[1.0])|      (1,[],[])|    (1,[0],[1.0])|      (4,[],[])|      (1,[],[])|[60.0,20437.0,913...|[1.10082783849643...|\n",
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+-----------+--------------+-------------+-----------+-------------+-----------+-----------+-------+-------------+---------------------+---------------------+-------------------+---------------+---------------+---------------+--------------------+-------------------+-----------------+-------------------+-----------------+-----------------+-------------+------------------+-----------------+---------------+-----------------+---------------+---------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_data_scaled.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save data to sliver bucket\n",
    "silver_bucket_path = \"s3a://sliver/preprocessed_loan_data\"\n",
    "loan_data_scaled.repartition(1).write.parquet(silver_bucket_path,  mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, rand\n",
    "\n",
    "\n",
    "loan_data_scaled = spark.read.parquet(silver_bucket_path)\n",
    "\n",
    "default_data = loan_data_scaled.filter(col(\"Default\") == 1)\n",
    "non_default_data = loan_data_scaled.filter(col(\"Default\") == 0)\n",
    "\n",
    "train_default, test_default = default_data.randomSplit([0.8, 0.2], seed=42)\n",
    "train_non_default, test_non_default = non_default_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "train_data = train_default.union(train_non_default)\n",
    "test_data = test_default.union(test_non_default)\n",
    "\n",
    "# Shuffle the data\n",
    "train_data = train_data.orderBy(rand(seed=42))\n",
    "test_data = test_data.orderBy(rand(seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LoanID',\n",
       " 'Age',\n",
       " 'Income',\n",
       " 'LoanAmount',\n",
       " 'CreditScore',\n",
       " 'MonthsEmployed',\n",
       " 'NumCreditLines',\n",
       " 'InterestRate',\n",
       " 'LoanTerm',\n",
       " 'DTIRatio',\n",
       " 'Education',\n",
       " 'EmploymentType',\n",
       " 'MaritalStatus',\n",
       " 'HasMortgage',\n",
       " 'HasDependents',\n",
       " 'LoanPurpose',\n",
       " 'HasCoSigner',\n",
       " 'Default',\n",
       " 'Income_filled',\n",
       " 'MonthsEmployed_filled',\n",
       " 'NumCreditLines_filled',\n",
       " 'InterestRate_filled',\n",
       " 'LoanTerm_filled',\n",
       " 'DTIRatio_filled',\n",
       " 'Education_index',\n",
       " 'EmploymentType_index',\n",
       " 'MaritalStatus_index',\n",
       " 'HasMortgage_index',\n",
       " 'HasDependents_index',\n",
       " 'LoanPurpose_index',\n",
       " 'HasCoSigner_index',\n",
       " 'Education_vec',\n",
       " 'EmploymentType_vec',\n",
       " 'MaritalStatus_vec',\n",
       " 'HasMortgage_vec',\n",
       " 'HasDependents_vec',\n",
       " 'LoanPurpose_vec',\n",
       " 'HasCoSigner_vec',\n",
       " 'features',\n",
       " 'scaled_features']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 153:===================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+----------+--------------+-------------+-----------+-------------+-----------+-----------+-------+-------------+---------------------+---------------------+-------------------+---------------+---------------+---------------+--------------------+-------------------+-----------------+-------------------+-----------------+-----------------+-------------+------------------+-----------------+---------------+-----------------+---------------+---------------+--------------------+--------------------+\n",
      "|    LoanID|Age|Income|LoanAmount|CreditScore|MonthsEmployed|NumCreditLines|InterestRate|LoanTerm|DTIRatio| Education|EmploymentType|MaritalStatus|HasMortgage|HasDependents|LoanPurpose|HasCoSigner|Default|Income_filled|MonthsEmployed_filled|NumCreditLines_filled|InterestRate_filled|LoanTerm_filled|DTIRatio_filled|Education_index|EmploymentType_index|MaritalStatus_index|HasMortgage_index|HasDependents_index|LoanPurpose_index|HasCoSigner_index|Education_vec|EmploymentType_vec|MaritalStatus_vec|HasMortgage_vec|HasDependents_vec|LoanPurpose_vec|HasCoSigner_vec|            features|     scaled_features|\n",
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+----------+--------------+-------------+-----------+-------------+-----------+-----------+-------+-------------+---------------------+---------------------+-------------------+---------------+---------------+---------------+--------------------+-------------------+-----------------+-------------------+-----------------+-----------------+-------------+------------------+-----------------+---------------+-----------------+---------------+---------------+--------------------+--------------------+\n",
      "|7YG865MCWP| 40| 25706|    218715|        722|            65|             4|       23.31|      36|    0.36|Bachelor's|     Full-time|     Divorced|        Yes|          Yes|   Business|         No|      0|        25706|                   65|                    4|              23.31|             36|           0.36|            0.0|                 3.0|                1.0|              0.0|                0.0|              0.0|              1.0|(3,[0],[1.0])|         (3,[],[])|    (2,[1],[1.0])|  (1,[0],[1.0])|    (1,[0],[1.0])|  (4,[0],[1.0])|      (1,[],[])|[40.0,25706.0,218...|[-0.2333719759002...|\n",
      "|BEHFNNEUT1| 26| 95203|    168039|        500|             7|             4|       14.38|      60|    0.12|  Master's|     Full-time|       Single|        Yes|           No|   Business|         No|      1|        95203|                    7|                    4|              14.38|             60|           0.12|            2.0|                 3.0|                2.0|              0.0|                1.0|              0.0|              1.0|(3,[2],[1.0])|         (3,[],[])|        (2,[],[])|  (1,[0],[1.0])|        (1,[],[])|  (4,[0],[1.0])|      (1,[],[])|[26.0,95203.0,168...|[-1.1673118459778...|\n",
      "|T6RFSXUUDJ| 53|108351|    119754|        485|            14|             2|       21.19|      12|    0.21|Bachelor's|     Part-time|       Single|        Yes|          Yes|       Home|         No|      0|       108351|                   14|                    2|              21.19|             12|           0.21|            0.0|                 0.0|                2.0|              0.0|                0.0|              1.0|              1.0|(3,[0],[1.0])|     (3,[0],[1.0])|        (2,[],[])|  (1,[0],[1.0])|    (1,[0],[1.0])|  (4,[1],[1.0])|      (1,[],[])|[53.0,108351.0,11...|[0.63385790345760...|\n",
      "|J2BKQP9IU7| 69| 87222|    136464|        636|           116|             1|        6.66|      12|    0.38|       PhD|     Part-time|       Single|         No|          Yes|  Education|        Yes|      0|        87222|                  116|                    1|               6.66|             12|           0.38|            3.0|                 0.0|                2.0|              1.0|                0.0|              2.0|              0.0|    (3,[],[])|     (3,[0],[1.0])|        (2,[],[])|      (1,[],[])|    (1,[0],[1.0])|  (4,[2],[1.0])|  (1,[0],[1.0])|[69.0,87222.0,136...|[1.70121775497492...|\n",
      "|XHZW2365P0| 22|141044|    117053|        446|            43|             2|        3.61|      12|    0.65|  Master's| Self-employed|      Married|         No|           No|       Auto|         No|      0|       141044|                   43|                    2|               3.61|             12|           0.65|            2.0|                 2.0|                0.0|              1.0|                1.0|              4.0|              1.0|(3,[2],[1.0])|     (3,[2],[1.0])|    (2,[0],[1.0])|      (1,[],[])|        (1,[],[])|      (4,[],[])|      (1,[],[])|[22.0,141044.0,11...|[-1.4341518088571...|\n",
      "+----------+---+------+----------+-----------+--------------+--------------+------------+--------+--------+----------+--------------+-------------+-----------+-------------+-----------+-----------+-------+-------------+---------------------+---------------------+-------------------+---------------+---------------+---------------+--------------------+-------------------+-----------------+-------------------+-----------------+-----------------+-------------+------------------+-----------------+---------------+-----------------+---------------+---------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_data.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.select([\"LoanID\", \"Default\",\"scaled_features\"])\n",
    "test_data = test_data.select([\"LoanID\", \"scaled_features\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/12 10:01:45 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "[Stage 143:===================================================>   (13 + 1) / 14]\r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"scaled_features\", labelCol=\"Default\", maxIter=10)\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "lr_predictions = lr_model.transform(test_data)\n",
    "\n",
    "# # Evaluate the model\n",
    "# evaluator = BinaryClassificationEvaluator(labelCol=\"Default\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "# roc_auc_lr = evaluator.evaluate(lr_predictions)\n",
    "# print(f\"Logistic Regression - ROC AUC: {roc_auc_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 146:===================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+----------+\n",
      "|    LoanID|     scaled_features|       rawPrediction|         probability|prediction|\n",
      "+----------+--------------------+--------------------+--------------------+----------+\n",
      "|7YG865MCWP|[-0.2333719759002...|[0.72563263496006...|[0.67384615368255...|       0.0|\n",
      "|BEHFNNEUT1|[-1.1673118459778...|[0.94084294360219...|[0.71926989664467...|       0.0|\n",
      "|T6RFSXUUDJ|[0.63385790345760...|[2.07950444896117...|[0.88889510180171...|       0.0|\n",
      "|J2BKQP9IU7|[1.70121775497492...|[4.58975430205908...|[0.98994674117806...|       0.0|\n",
      "|XHZW2365P0|[-1.4341518088571...|[2.48290005141437...|[0.92293432170609...|       0.0|\n",
      "+----------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr_predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 150:===================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|    LoanID|prediction|\n",
      "+----------+----------+\n",
      "|7YG865MCWP|       0.0|\n",
      "|BEHFNNEUT1|       0.0|\n",
      "|T6RFSXUUDJ|       0.0|\n",
      "|J2BKQP9IU7|       0.0|\n",
      "|XHZW2365P0|       0.0|\n",
      "|AYDNIXAW5E|       0.0|\n",
      "|H2BOVDFE2S|       0.0|\n",
      "|V4138GAD7D|       0.0|\n",
      "|LNLSA61H9Q|       0.0|\n",
      "|3D0HETFVI6|       0.0|\n",
      "|B712U8QUQ9|       0.0|\n",
      "|7Q88O1GE0G|       0.0|\n",
      "|23HB3DMK4A|       0.0|\n",
      "|O5O1CP51BP|       0.0|\n",
      "|YCKGYY5D3N|       0.0|\n",
      "|8SGQPYYZDJ|       0.0|\n",
      "|C1ZRTUW8IW|       0.0|\n",
      "|FQCG7SQCJN|       0.0|\n",
      "|Q8BZ3B8A4G|       0.0|\n",
      "|RKFHCA9JQE|       0.0|\n",
      "+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Result: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Result:\", lr_predictions.select(\"LoanID\", \"prediction\").show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"Default\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy_lr = accuracy_evaluator.evaluate(lr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8850444687158683\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path /home/drissdo/Desktop/Scalable-Distributed-Systems/ML/model already exists. Consider removing it or choosing a new path.\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "model_path = \"/home/drissdo/Desktop/Scalable-Distributed-Systems/ML/model\"\n",
    "\n",
    "\n",
    "import os\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Path {model_path} already exists. Consider removing it or choosing a new path.\")\n",
    "\n",
    "# Save the model\n",
    "lr_model.write().overwrite().save(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - ROC AUC: 0.7336530388666921\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "# Load the saved model\n",
    "loadedModel = LogisticRegressionModel.load(model_path)\n",
    "\n",
    "# Verify by making predictions using the loaded model\n",
    "lr_predictions = loadedModel.transform(test_data)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"Default\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "roc_auc_lr = evaluator.evaluate(lr_predictions)\n",
    "print(f\"Logistic Regression - ROC AUC: {roc_auc_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 188:===================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - ROC AUC: 0.4210816058940954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(featuresCol=\"scaled_features\", labelCol=\"Default\", maxDepth=10)\n",
    "dt_model = dt.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "dt_predictions = dt_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "roc_auc_dt = evaluator.evaluate(dt_predictions)\n",
    "print(f\"Decision Tree - ROC AUC: {roc_auc_dt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 243:===================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - ROC AUC: 0.7071944814368916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol=\"scaled_features\", labelCol=\"Default\", numTrees=100, maxDepth=5)\n",
    "rf_model = rf.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "rf_predictions = rf_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "roc_auc_rf = evaluator.evaluate(rf_predictions)\n",
    "print(f\"Random Forest - ROC AUC: {roc_auc_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient-Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 424:===================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient-Boosted Trees - ROC AUC: 0.7311417017458507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "gbt = GBTClassifier(featuresCol=\"scaled_features\", labelCol=\"Default\", maxIter=10, maxDepth=5)\n",
    "gbt_model = gbt.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "gbt_predictions = gbt_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "roc_auc_gbt = evaluator.evaluate(gbt_predictions)\n",
    "print(f\"Gradient-Boosted Trees - ROC AUC: {roc_auc_gbt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy: 0.8850444687158683, Precision: 0.8498232051102164, Recall: 0.8850444687158684, F1 Score: 0.8354146891676907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Accuracy: 0.8822554220627243, Precision: 0.8370298576990229, Recall: 0.8822554220627243, F1 Score: 0.841067195133172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Accuracy: 0.8844008425651427, Precision: 0.7821648503299344, Recall: 0.8844008425651427, F1 Score: 0.8301469970319177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 532:===================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient-Boosted Trees - Accuracy: 0.8852980184116087, Precision: 0.8498310312720517, Recall: 0.8852980184116087, F1 Score: 0.8382626093184488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Define evaluators\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"Default\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"Default\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"Default\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"Default\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "accuracy_lr = accuracy_evaluator.evaluate(lr_predictions)\n",
    "precision_lr = precision_evaluator.evaluate(lr_predictions)\n",
    "recall_lr = recall_evaluator.evaluate(lr_predictions)\n",
    "f1_lr = f1_evaluator.evaluate(lr_predictions)\n",
    "\n",
    "print(f\"Logistic Regression - Accuracy: {accuracy_lr}, Precision: {precision_lr}, Recall: {recall_lr}, F1 Score: {f1_lr}\")\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "accuracy_dt = accuracy_evaluator.evaluate(dt_predictions)\n",
    "precision_dt = precision_evaluator.evaluate(dt_predictions)\n",
    "recall_dt = recall_evaluator.evaluate(dt_predictions)\n",
    "f1_dt = f1_evaluator.evaluate(dt_predictions)\n",
    "\n",
    "print(f\"Decision Tree - Accuracy: {accuracy_dt}, Precision: {precision_dt}, Recall: {recall_dt}, F1 Score: {f1_dt}\")\n",
    "\n",
    "# Evaluate Random Forest\n",
    "accuracy_rf = accuracy_evaluator.evaluate(rf_predictions)\n",
    "precision_rf = precision_evaluator.evaluate(rf_predictions)\n",
    "recall_rf = recall_evaluator.evaluate(rf_predictions)\n",
    "f1_rf = f1_evaluator.evaluate(rf_predictions)\n",
    "\n",
    "print(f\"Random Forest - Accuracy: {accuracy_rf}, Precision: {precision_rf}, Recall: {recall_rf}, F1 Score: {f1_rf}\")\n",
    "\n",
    "# Evaluate Gradient-Boosted Trees\n",
    "accuracy_gbt = accuracy_evaluator.evaluate(gbt_predictions)\n",
    "precision_gbt = precision_evaluator.evaluate(gbt_predictions)\n",
    "recall_gbt = recall_evaluator.evaluate(gbt_predictions)\n",
    "f1_gbt = f1_evaluator.evaluate(gbt_predictions)\n",
    "\n",
    "print(f\"Gradient-Boosted Trees - Accuracy: {accuracy_gbt}, Precision: {precision_gbt}, Recall: {recall_gbt}, F1 Score: {f1_gbt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validated Model - ROC AUC: 0.7380937269287152\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# # Define parameter grid\n",
    "# paramGrid = ParamGridBuilder() \\\n",
    "#     .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "#     .addGrid(dt.maxDepth, [3, 5]) \\\n",
    "#     .addGrid(rf.numTrees, [50, 100]) \\\n",
    "#     .addGrid(gbt.maxIter, [5, 10]) \\\n",
    "#     .build()\n",
    "\n",
    "# # Define cross-validator\n",
    "# crossval = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "# # Fit the model\n",
    "# cvModel = crossval.fit(train_data)\n",
    "\n",
    "# # Make predictions\n",
    "# cv_predictions = cvModel.transform(test_data)\n",
    "\n",
    "# # Evaluate the model\n",
    "# roc_auc_cv = evaluator.evaluate(cv_predictions)\n",
    "# print(f\"Cross-Validated Model - ROC AUC: {roc_auc_cv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
